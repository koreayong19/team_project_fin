{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
   "metadata": {},
   "source": [
    "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
    "- 이미지 binary 분류 과제\n",
    "- 담당: 이녕민M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4325d39-6344-4116-b343-df51696905ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \n",
      "Get:10 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2564 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]   \n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3002 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1468 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [783 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2247 kB]\n",
      "Fetched 10.3 MB in 4s (2508 kB/s)                           \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python3-opencv is already the newest version (3.2.0+dfsg-4ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 78 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y python3-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c541d56e-7985-49f3-99fe-25378f084196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f475804-13db-484c-a348-f01580e80a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
   "metadata": {},
   "source": [
    "## Set Arguments & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드(seed) 설정\n",
    "\n",
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= 'data'\n",
    "NUM_CLS = 2\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "INPUT_SHAPE = 128\n",
    "\n",
    "####\n",
    "k = 5\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train & Validation Set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04642777-c2e0-439b-9692-f6c571a86521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.8)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.8):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['COVID']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class custom_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(custom_CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        output = self.softmax(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056905-1f77-4579-a260-07bb1056f6db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utils\n",
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, fold, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            \n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "            \n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Fold{fold +1} /Epoch{epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, fold, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Fold{fold + 1} Epoch/{epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train\n",
    "### 학습을 위한 객체 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 516 Val set samples: 130\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "###\n",
    "dataset = ConcatDataset([train_dataset, validation_dataset])\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "####\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40b74ea6-cbdf-4ade-8350-20c3dcbbce9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   3,   4,   5,   7,   8,   9,  11,  12,  13,  14,  15,\n",
      "        16,  17,  18,  19,  20,  21,  22,  23,  25,  26,  27,  28,  29,\n",
      "        32,  33,  34,  35,  36,  37,  38,  40,  42,  43,  45,  46,  47,\n",
      "        48,  50,  51,  52,  53,  57,  58,  59,  61,  62,  64,  66,  67,\n",
      "        68,  71,  73,  74,  75,  79,  80,  83,  84,  85,  87,  88,  89,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 102, 103, 104,\n",
      "       105, 106, 107, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121,\n",
      "       122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 136, 137, 138,\n",
      "       139, 140, 141, 142, 143, 144, 146, 147, 149, 150, 151, 152, 153,\n",
      "       154, 156, 157, 159, 160, 161, 162, 164, 166, 168, 169, 170, 171,\n",
      "       172, 173, 175, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188,\n",
      "       189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
      "       203, 205, 206, 207, 210, 212, 214, 216, 217, 219, 220, 222, 223,\n",
      "       224, 225, 226, 228, 229, 230, 232, 233, 234, 235, 237, 238, 239,\n",
      "       240, 241, 242, 243, 244, 245, 246, 247, 249, 251, 252, 253, 254,\n",
      "       255, 258, 259, 260, 261, 262, 263, 266, 267, 269, 270, 272, 273,\n",
      "       274, 275, 276, 277, 278, 279, 280, 282, 283, 285, 286, 287, 288,\n",
      "       289, 290, 293, 294, 295, 297, 298, 299, 300, 301, 303, 304, 306,\n",
      "       307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322,\n",
      "       323, 324, 325, 327, 328, 330, 333, 334, 335, 336, 337, 339, 342,\n",
      "       343, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357,\n",
      "       358, 359, 360, 362, 365, 366, 368, 369, 371, 372, 373, 374, 375,\n",
      "       376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
      "       389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401,\n",
      "       402, 403, 405, 406, 408, 410, 411, 412, 413, 414, 415, 416, 417,\n",
      "       418, 419, 420, 422, 423, 424, 425, 426, 427, 429, 430, 431, 432,\n",
      "       433, 434, 435, 437, 438, 439, 440, 441, 442, 445, 447, 448, 449,\n",
      "       450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
      "       463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "       476, 480, 481, 482, 483, 484, 485, 488, 489, 490, 491, 492, 493,\n",
      "       495, 496, 497, 498, 499, 500, 501, 502, 504, 505, 507, 508, 509,\n",
      "       510, 511, 513, 514, 516, 517, 519, 520, 521, 522, 523, 524, 525,\n",
      "       526, 527, 529, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542,\n",
      "       543, 544, 545, 547, 548, 549, 550, 553, 555, 556, 557, 558, 559,\n",
      "       560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
      "       573, 574, 575, 577, 578, 579, 581, 582, 583, 584, 585, 586, 587,\n",
      "       588, 589, 590, 591, 592, 594, 595, 596, 597, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 610, 612, 613, 614, 617, 618, 619, 620,\n",
      "       621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 634,\n",
      "       635, 636, 637, 638, 639, 640, 643, 644, 645]), array([  2,   6,  10,  24,  30,  31,  39,  41,  44,  49,  54,  55,  56,\n",
      "        60,  63,  65,  69,  70,  72,  76,  77,  78,  81,  82,  86,  90,\n",
      "       101, 108, 109, 110, 118, 131, 132, 133, 135, 145, 148, 155, 158,\n",
      "       163, 165, 167, 174, 176, 177, 181, 192, 204, 208, 209, 211, 213,\n",
      "       215, 218, 221, 227, 231, 236, 248, 250, 256, 257, 264, 265, 268,\n",
      "       271, 281, 284, 291, 292, 296, 302, 305, 310, 320, 321, 326, 329,\n",
      "       331, 332, 338, 340, 341, 344, 349, 361, 363, 364, 367, 370, 404,\n",
      "       407, 409, 421, 428, 436, 443, 444, 446, 477, 478, 479, 486, 487,\n",
      "       494, 503, 506, 512, 515, 518, 528, 530, 531, 537, 546, 551, 552,\n",
      "       554, 576, 580, 593, 598, 599, 609, 611, 615, 616, 633, 641, 642]))\n",
      "(array([  1,   2,   3,   4,   5,   6,   8,  10,  12,  13,  14,  16,  17,\n",
      "        19,  20,  21,  24,  25,  26,  27,  30,  31,  32,  34,  35,  36,\n",
      "        37,  38,  39,  40,  41,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,\n",
      "        67,  69,  70,  71,  72,  74,  76,  77,  78,  80,  81,  82,  85,\n",
      "        86,  87,  90,  91,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 118, 119,\n",
      "       120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "       133, 134, 135, 136, 138, 139, 141, 142, 143, 145, 146, 147, 148,\n",
      "       149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
      "       163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "       176, 177, 179, 180, 181, 183, 185, 186, 187, 189, 190, 191, 192,\n",
      "       193, 194, 195, 197, 198, 200, 201, 202, 204, 205, 206, 207, 208,\n",
      "       209, 211, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224,\n",
      "       225, 226, 227, 229, 230, 231, 232, 233, 236, 237, 239, 240, 241,\n",
      "       242, 243, 245, 246, 248, 250, 251, 252, 253, 254, 255, 256, 257,\n",
      "       258, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 276, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 291,\n",
      "       292, 293, 294, 295, 296, 297, 301, 302, 303, 305, 306, 307, 308,\n",
      "       309, 310, 313, 314, 315, 316, 317, 320, 321, 322, 323, 324, 325,\n",
      "       326, 329, 330, 331, 332, 337, 338, 339, 340, 341, 342, 343, 344,\n",
      "       345, 346, 347, 348, 349, 350, 351, 353, 355, 358, 359, 361, 362,\n",
      "       363, 364, 365, 366, 367, 368, 370, 371, 372, 373, 376, 377, 378,\n",
      "       379, 380, 381, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
      "       393, 394, 395, 396, 397, 400, 401, 402, 403, 404, 406, 407, 408,\n",
      "       409, 410, 411, 412, 413, 414, 415, 418, 419, 420, 421, 422, 423,\n",
      "       424, 426, 427, 428, 431, 432, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 448, 449, 450, 451, 453, 454, 455, 457,\n",
      "       458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 471,\n",
      "       472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "       485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 498, 499,\n",
      "       500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512,\n",
      "       513, 514, 515, 517, 518, 520, 521, 522, 524, 525, 527, 528, 529,\n",
      "       530, 531, 534, 535, 536, 537, 538, 539, 540, 542, 543, 544, 545,\n",
      "       546, 547, 548, 550, 551, 552, 554, 555, 556, 557, 560, 561, 562,\n",
      "       563, 564, 565, 566, 568, 569, 571, 572, 573, 574, 576, 578, 579,\n",
      "       580, 583, 584, 585, 586, 587, 589, 591, 592, 593, 594, 595, 596,\n",
      "       597, 598, 599, 600, 602, 606, 607, 608, 609, 610, 611, 612, 614,\n",
      "       615, 616, 618, 619, 622, 623, 624, 625, 626, 628, 630, 632, 633,\n",
      "       634, 635, 636, 637, 639, 640, 641, 642, 643, 645]), array([  0,   7,   9,  11,  15,  18,  22,  23,  28,  29,  33,  42,  43,\n",
      "        61,  66,  68,  73,  75,  79,  83,  84,  88,  89,  92,  93, 104,\n",
      "       114, 116, 117, 137, 140, 144, 153, 178, 182, 184, 188, 196, 199,\n",
      "       203, 210, 212, 220, 228, 234, 235, 238, 244, 247, 249, 259, 260,\n",
      "       274, 275, 277, 278, 289, 290, 298, 299, 300, 304, 311, 312, 318,\n",
      "       319, 327, 328, 333, 334, 335, 336, 352, 354, 356, 357, 360, 369,\n",
      "       374, 375, 382, 398, 399, 405, 416, 417, 425, 429, 430, 433, 434,\n",
      "       447, 452, 456, 468, 496, 497, 516, 519, 523, 526, 532, 533, 541,\n",
      "       549, 553, 558, 559, 567, 570, 575, 577, 581, 582, 588, 590, 601,\n",
      "       603, 604, 605, 613, 617, 620, 621, 627, 629, 631, 638, 644]))\n",
      "(array([  0,   1,   2,   4,   6,   7,   8,   9,  10,  11,  13,  14,  15,\n",
      "        18,  20,  21,  22,  23,  24,  27,  28,  29,  30,  31,  32,  33,\n",
      "        34,  35,  36,  38,  39,  40,  41,  42,  43,  44,  47,  49,  51,\n",
      "        52,  53,  54,  55,  56,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "        66,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,  79,  80,\n",
      "        81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 104, 105, 106, 108, 109,\n",
      "       110, 111, 112, 114, 115, 116, 117, 118, 120, 121, 122, 123, 125,\n",
      "       127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "       140, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 156, 158,\n",
      "       159, 160, 161, 163, 164, 165, 166, 167, 170, 171, 174, 176, 177,\n",
      "       178, 179, 181, 182, 183, 184, 186, 187, 188, 189, 191, 192, 196,\n",
      "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210,\n",
      "       211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224,\n",
      "       227, 228, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241,\n",
      "       242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256,\n",
      "       257, 258, 259, 260, 262, 264, 265, 266, 267, 268, 269, 270, 271,\n",
      "       273, 274, 275, 276, 277, 278, 279, 281, 282, 284, 288, 289, 290,\n",
      "       291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 302, 303, 304,\n",
      "       305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 317, 318, 319,\n",
      "       320, 321, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333,\n",
      "       334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 347,\n",
      "       348, 349, 351, 352, 354, 356, 357, 358, 359, 360, 361, 363, 364,\n",
      "       366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 378, 379,\n",
      "       382, 384, 385, 386, 387, 389, 391, 392, 394, 397, 398, 399, 400,\n",
      "       401, 402, 404, 405, 406, 407, 409, 410, 413, 415, 416, 417, 418,\n",
      "       419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 432, 433,\n",
      "       434, 435, 436, 438, 439, 441, 443, 444, 445, 446, 447, 450, 451,\n",
      "       452, 454, 455, 456, 457, 458, 459, 460, 461, 462, 464, 465, 466,\n",
      "       467, 468, 470, 471, 472, 474, 475, 476, 477, 478, 479, 480, 482,\n",
      "       484, 485, 486, 487, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
      "       498, 499, 501, 502, 503, 504, 505, 506, 508, 509, 510, 512, 513,\n",
      "       515, 516, 518, 519, 520, 521, 523, 524, 525, 526, 527, 528, 529,\n",
      "       530, 531, 532, 533, 534, 535, 537, 538, 539, 540, 541, 543, 545,\n",
      "       546, 547, 549, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560,\n",
      "       561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
      "       575, 576, 577, 580, 581, 582, 584, 586, 587, 588, 590, 593, 595,\n",
      "       597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 609, 611, 612,\n",
      "       613, 614, 615, 616, 617, 620, 621, 625, 627, 628, 629, 630, 631,\n",
      "       633, 634, 635, 638, 639, 640, 641, 642, 643, 644]), array([  3,   5,  12,  16,  17,  19,  25,  26,  37,  45,  46,  48,  50,\n",
      "        57,  67,  74,  94, 103, 107, 113, 119, 124, 126, 141, 142, 149,\n",
      "       152, 154, 157, 162, 168, 169, 172, 173, 175, 180, 185, 190, 193,\n",
      "       194, 195, 207, 222, 225, 226, 229, 237, 245, 255, 261, 263, 272,\n",
      "       280, 283, 285, 286, 287, 301, 309, 316, 322, 346, 350, 353, 355,\n",
      "       362, 365, 377, 380, 381, 383, 388, 390, 393, 395, 396, 403, 408,\n",
      "       411, 412, 414, 426, 431, 437, 440, 442, 448, 449, 453, 463, 469,\n",
      "       473, 481, 483, 488, 500, 507, 511, 514, 517, 522, 536, 542, 544,\n",
      "       548, 550, 574, 578, 579, 583, 585, 589, 591, 592, 594, 596, 607,\n",
      "       608, 610, 618, 619, 622, 623, 624, 626, 632, 636, 637, 645]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  35,  37,  39,  40,  41,\n",
      "        42,  43,  44,  45,  46,  47,  48,  49,  50,  52,  54,  55,  56,\n",
      "        57,  58,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "        71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  98,\n",
      "        99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114,\n",
      "       116, 117, 118, 119, 121, 124, 126, 128, 130, 131, 132, 133, 134,\n",
      "       135, 137, 138, 140, 141, 142, 144, 145, 148, 149, 152, 153, 154,\n",
      "       155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168,\n",
      "       169, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184,\n",
      "       185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 199, 200,\n",
      "       201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n",
      "       215, 216, 217, 218, 220, 221, 222, 225, 226, 227, 228, 229, 230,\n",
      "       231, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247,\n",
      "       248, 249, 250, 251, 252, 255, 256, 257, 259, 260, 261, 263, 264,\n",
      "       265, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280,\n",
      "       281, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 295, 296,\n",
      "       298, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 312, 313,\n",
      "       315, 316, 318, 319, 320, 321, 322, 326, 327, 328, 329, 330, 331,\n",
      "       332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345,\n",
      "       346, 349, 350, 352, 353, 354, 355, 356, 357, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 369, 370, 372, 374, 375, 377, 378, 379, 380,\n",
      "       381, 382, 383, 385, 387, 388, 389, 390, 391, 392, 393, 395, 396,\n",
      "       397, 398, 399, 401, 403, 404, 405, 406, 407, 408, 409, 411, 412,\n",
      "       413, 414, 416, 417, 418, 421, 425, 426, 427, 428, 429, 430, 431,\n",
      "       433, 434, 435, 436, 437, 440, 442, 443, 444, 446, 447, 448, 449,\n",
      "       452, 453, 454, 455, 456, 458, 459, 460, 461, 463, 466, 468, 469,\n",
      "       471, 473, 474, 475, 476, 477, 478, 479, 481, 483, 484, 486, 487,\n",
      "       488, 489, 491, 492, 494, 496, 497, 498, 500, 502, 503, 504, 506,\n",
      "       507, 508, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 522,\n",
      "       523, 526, 528, 530, 531, 532, 533, 536, 537, 539, 540, 541, 542,\n",
      "       544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 570, 572, 574, 575,\n",
      "       576, 577, 578, 579, 580, 581, 582, 583, 585, 586, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 598, 599, 600, 601, 602, 603, 604,\n",
      "       605, 606, 607, 608, 609, 610, 611, 613, 614, 615, 616, 617, 618,\n",
      "       619, 620, 621, 622, 623, 624, 626, 627, 628, 629, 630, 631, 632,\n",
      "       633, 636, 637, 638, 640, 641, 642, 643, 644, 645]), array([  8,  36,  38,  51,  53,  59,  96,  97, 100, 111, 112, 115, 120,\n",
      "       122, 123, 125, 127, 129, 136, 139, 143, 146, 147, 150, 151, 164,\n",
      "       171, 179, 183, 186, 197, 198, 202, 219, 223, 224, 232, 233, 239,\n",
      "       246, 253, 254, 258, 262, 266, 267, 279, 282, 293, 294, 297, 303,\n",
      "       306, 307, 314, 317, 323, 324, 325, 342, 347, 348, 351, 358, 359,\n",
      "       368, 371, 373, 376, 384, 386, 394, 400, 402, 410, 415, 419, 420,\n",
      "       422, 423, 424, 432, 438, 439, 441, 445, 450, 451, 457, 462, 464,\n",
      "       465, 467, 470, 472, 480, 482, 485, 490, 493, 495, 499, 501, 505,\n",
      "       509, 513, 521, 524, 525, 527, 529, 534, 535, 538, 543, 556, 557,\n",
      "       568, 569, 571, 573, 584, 587, 597, 612, 625, 634, 635, 639]))\n",
      "(array([  0,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  15,  16,\n",
      "        17,  18,  19,  22,  23,  24,  25,  26,  28,  29,  30,  31,  33,\n",
      "        36,  37,  38,  39,  41,  42,  43,  44,  45,  46,  48,  49,  50,\n",
      "        51,  53,  54,  55,  56,  57,  59,  60,  61,  63,  65,  66,  67,\n",
      "        68,  69,  70,  72,  73,  74,  75,  76,  77,  78,  79,  81,  82,\n",
      "        83,  84,  86,  88,  89,  90,  92,  93,  94,  96,  97, 100, 101,\n",
      "       103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "       118, 119, 120, 122, 123, 124, 125, 126, 127, 129, 131, 132, 133,\n",
      "       135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
      "       149, 150, 151, 152, 153, 154, 155, 157, 158, 162, 163, 164, 165,\n",
      "       167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "       181, 182, 183, 184, 185, 186, 188, 190, 192, 193, 194, 195, 196,\n",
      "       197, 198, 199, 202, 203, 204, 207, 208, 209, 210, 211, 212, 213,\n",
      "       215, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "       231, 232, 233, 234, 235, 236, 237, 238, 239, 244, 245, 246, 247,\n",
      "       248, 249, 250, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
      "       263, 264, 265, 266, 267, 268, 271, 272, 274, 275, 277, 278, 279,\n",
      "       280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 293,\n",
      "       294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "       309, 310, 311, 312, 314, 316, 317, 318, 319, 320, 321, 322, 323,\n",
      "       324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 338,\n",
      "       340, 341, 342, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368,\n",
      "       369, 370, 371, 373, 374, 375, 376, 377, 380, 381, 382, 383, 384,\n",
      "       386, 388, 390, 393, 394, 395, 396, 398, 399, 400, 402, 403, 404,\n",
      "       405, 407, 408, 409, 410, 411, 412, 414, 415, 416, 417, 419, 420,\n",
      "       421, 422, 423, 424, 425, 426, 428, 429, 430, 431, 432, 433, 434,\n",
      "       436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "       449, 450, 451, 452, 453, 456, 457, 462, 463, 464, 465, 467, 468,\n",
      "       469, 470, 472, 473, 477, 478, 479, 480, 481, 482, 483, 485, 486,\n",
      "       487, 488, 490, 493, 494, 495, 496, 497, 499, 500, 501, 503, 505,\n",
      "       506, 507, 509, 511, 512, 513, 514, 515, 516, 517, 518, 519, 521,\n",
      "       522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
      "       535, 536, 537, 538, 541, 542, 543, 544, 546, 548, 549, 550, 551,\n",
      "       552, 553, 554, 556, 557, 558, 559, 567, 568, 569, 570, 571, 573,\n",
      "       574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 587,\n",
      "       588, 589, 590, 591, 592, 593, 594, 596, 597, 598, 599, 601, 603,\n",
      "       604, 605, 607, 608, 609, 610, 611, 612, 613, 615, 616, 617, 618,\n",
      "       619, 620, 621, 622, 623, 624, 625, 626, 627, 629, 631, 632, 633,\n",
      "       634, 635, 636, 637, 638, 639, 641, 642, 644, 645]), array([  1,   4,  13,  14,  20,  21,  27,  32,  34,  35,  40,  47,  52,\n",
      "        58,  62,  64,  71,  80,  85,  87,  91,  95,  98,  99, 102, 105,\n",
      "       106, 121, 128, 130, 134, 138, 156, 159, 160, 161, 166, 170, 187,\n",
      "       189, 191, 200, 201, 205, 206, 214, 216, 217, 230, 240, 241, 242,\n",
      "       243, 251, 252, 269, 270, 273, 276, 288, 295, 308, 313, 315, 330,\n",
      "       337, 339, 343, 345, 366, 372, 378, 379, 385, 387, 389, 391, 392,\n",
      "       397, 401, 406, 413, 418, 427, 435, 454, 455, 458, 459, 460, 461,\n",
      "       466, 471, 474, 475, 476, 484, 489, 491, 492, 498, 502, 504, 508,\n",
      "       510, 520, 539, 540, 545, 547, 555, 560, 561, 562, 563, 564, 565,\n",
      "       566, 572, 586, 595, 600, 602, 606, 614, 628, 630, 640, 643]))\n"
     ]
    }
   ],
   "source": [
    "for i in splits.split(np.arange(len(dataset))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
   "metadata": {},
   "source": [
    "#### Load model and other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = custom_CNN(NUM_CLS).to(DEVICE)\n",
    "\n",
    "# # Save Initial Model\n",
    "# torch.save(model.state_dict(), 'initial.pt')\n",
    "\n",
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(dataset))\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = get_metric_fn\n",
    "\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_CNN(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 25, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=21025, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc632533-0e5e-4d29-94ae-ad581b38fa90",
   "metadata": {},
   "source": [
    "# K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7da0ffd6-dcb6-46f0-9fbb-896f2c9cac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold1 /Epoch0, Train loss: 0.7354282848536968, Acc: 0.5290697674418605, F1-Macro: 0.3671587553940494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:44<06:43, 44.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Epoch/0, Val loss: 0.8664253205060959, Acc: 0.5384615384615384, F1-Macro: 0.364613880742913\n",
      "Fold1 /Epoch1, Train loss: 0.7345821000635624, Acc: 0.5329457364341085, F1-Macro: 0.3723673253085018\n",
      "Fold1 Epoch/1, Val loss: 0.8619551956653595, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Validation loss decreased 0.8664253205060959 -> 0.8619551956653595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:27<05:53, 44.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch2, Train loss: 0.7344596311450005, Acc: 0.5310077519379846, F1-Macro: 0.3612685421994885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:20<05:26, 46.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Epoch/2, Val loss: 0.85556261241436, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Validation loss decreased 0.8619551956653595 -> 0.85556261241436\n",
      "Fold1 /Epoch3, Train loss: 0.7316707111895084, Acc: 0.5251937984496124, F1-Macro: 0.34434561626429483\n",
      "Fold1 Epoch/3, Val loss: 0.8589966148138046, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [03:10<04:47, 47.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch4, Train loss: 0.7231788970530033, Acc: 0.5329457364341085, F1-Macro: 0.3656309461258678\n",
      "Fold1 Epoch/4, Val loss: 0.8504694849252701, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Validation loss decreased 0.85556261241436 -> 0.8504694849252701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [03:58<03:59, 47.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch5, Train loss: 0.7203449010848999, Acc: 0.5251937984496124, F1-Macro: 0.34434561626429483\n",
      "Fold1 Epoch/5, Val loss: 0.8431991785764694, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Validation loss decreased 0.8504694849252701 -> 0.8431991785764694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [04:57<03:25, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch6, Train loss: 0.7021193280816078, Acc: 0.6550387596899225, F1-Macro: 0.6386156533782402\n",
      "Fold1 Epoch/6, Val loss: 0.807050958275795, Acc: 0.6615384615384615, F1-Macro: 0.6474358974358975\n",
      "Validation loss decreased 0.8431991785764694 -> 0.807050958275795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [05:57<02:41, 53.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch7, Train loss: 0.6811111830174923, Acc: 0.6569767441860465, F1-Macro: 0.6427417493653358\n",
      "Fold1 Epoch/7, Val loss: 0.832627609372139, Acc: 0.6923076923076923, F1-Macro: 0.6920161099265577\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [06:55<01:50, 55.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch8, Train loss: 0.677888311445713, Acc: 0.6337209302325582, F1-Macro: 0.6303879024464194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [07:53<00:55, 55.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Epoch/8, Val loss: 0.792502760887146, Acc: 0.5923076923076923, F1-Macro: 0.5310053774419713\n",
      "Validation loss decreased 0.807050958275795 -> 0.792502760887146\n",
      "Fold1 /Epoch9, Train loss: 0.6442344821989536, Acc: 0.6841085271317829, F1-Macro: 0.6833652698668455\n",
      "Fold1 Epoch/9, Val loss: 0.9062233567237854, Acc: 0.6615384615384615, F1-Macro: 0.6334273263265828\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [08:49<00:00, 52.93s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "Fold2 /Epoch0, Train loss: 0.6242380701005459, Acc: 0.6924564796905223, F1-Macro: 0.6888053514440494\n",
      "Fold2 Epoch/0, Val loss: 0.6632287688553333, Acc: 0.6976744186046512, F1-Macro: 0.6929508696978944\n",
      "Validation loss decreased 0.792502760887146 -> 0.6632287688553333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:58<08:46, 58.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch1, Train loss: 0.5779644213616848, Acc: 0.7408123791102514, F1-Macro: 0.7407648555605448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:57<07:50, 58.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Epoch/1, Val loss: 0.7129128724336624, Acc: 0.7209302325581395, F1-Macro: 0.7159980430528377\n",
      "Early stopping counter 1/10\n",
      "Fold2 /Epoch2, Train loss: 0.5489104092121124, Acc: 0.7678916827852998, F1-Macro: 0.7677865612648223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:54<06:46, 58.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Epoch/2, Val loss: 0.945597305893898, Acc: 0.751937984496124, F1-Macro: 0.751205400192864\n",
      "Early stopping counter 2/10\n",
      "Fold2 /Epoch3, Train loss: 0.5302366204559803, Acc: 0.7756286266924565, F1-Macro: 0.7740657022302593\n",
      "Fold2 Epoch/3, Val loss: 0.6181008890271187, Acc: 0.7674418604651163, F1-Macro: 0.7667550626808101\n",
      "Validation loss decreased 0.6632287688553333 -> 0.6181008890271187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [03:54<05:51, 58.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch4, Train loss: 0.4782049171626568, Acc: 0.7949709864603481, F1-Macro: 0.7948781291172595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [04:53<04:54, 58.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Epoch/4, Val loss: 0.5622198432683945, Acc: 0.7674418604651163, F1-Macro: 0.7674278846153846\n",
      "Validation loss decreased 0.6181008890271187 -> 0.5622198432683945\n",
      "Fold2 /Epoch5, Train loss: 0.4494655281305313, Acc: 0.8143133462282398, F1-Macro: 0.8142570581719111\n",
      "Fold2 Epoch/5, Val loss: 0.549200251698494, Acc: 0.751937984496124, F1-Macro: 0.7485380116959064\n",
      "Validation loss decreased 0.5622198432683945 -> 0.549200251698494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [05:52<03:55, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch6, Train loss: 0.44642251171171665, Acc: 0.7988394584139265, F1-Macro: 0.7988025744649004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [06:49<02:55, 58.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Epoch/6, Val loss: 0.5185106713324785, Acc: 0.751937984496124, F1-Macro: 0.7475538160469668\n",
      "Validation loss decreased 0.549200251698494 -> 0.5185106713324785\n",
      "Fold2 /Epoch7, Train loss: 0.4448530189692974, Acc: 0.804642166344294, F1-Macro: 0.8027976993001975\n",
      "Fold2 Epoch/7, Val loss: 0.7362904502078891, Acc: 0.6124031007751938, F1-Macro: 0.5852623456790124\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [07:48<01:57, 58.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch8, Train loss: 0.38271416537463665, Acc: 0.8239845261121856, F1-Macro: 0.8239423706614277\n",
      "Fold2 Epoch/8, Val loss: 0.5677460581064224, Acc: 0.7751937984496124, F1-Macro: 0.7738347137416117\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [08:48<00:58, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch9, Train loss: 0.3567410921677947, Acc: 0.8626692456479691, F1-Macro: 0.8623726627498471\n",
      "Fold2 Epoch/9, Val loss: 1.0484667792916298, Acc: 0.751937984496124, F1-Macro: 0.7519230769230769\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [09:46<00:00, 58.70s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "Fold3 /Epoch0, Train loss: 0.37428366020321846, Acc: 0.8549323017408124, F1-Macro: 0.8545055439860416\n",
      "Fold3 Epoch/0, Val loss: 0.2898934781551361, Acc: 0.9689922480620154, F1-Macro: 0.9689754689754689\n",
      "Validation loss decreased 0.5185106713324785 -> 0.2898934781551361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:58<08:45, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch1, Train loss: 0.35285443253815174, Acc: 0.8646034816247582, F1-Macro: 0.8642861428614286\n",
      "Fold3 Epoch/1, Val loss: 0.3094054879620671, Acc: 0.8604651162790697, F1-Macro: 0.8573710073710075\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:53<07:39, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch2, Train loss: 0.3366191927343607, Acc: 0.8800773694390716, F1-Macro: 0.8793183940242764\n",
      "Fold3 Epoch/2, Val loss: 0.4216200113296509, Acc: 0.8682170542635659, F1-Macro: 0.8670667394071649\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:49<06:38, 56.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch3, Train loss: 0.29593106731772423, Acc: 0.8781431334622823, F1-Macro: 0.877784656948275\n",
      "Fold3 Epoch/3, Val loss: 0.24897774308919907, Acc: 0.9457364341085271, F1-Macro: 0.9456842105263158\n",
      "Validation loss decreased 0.2898934781551361 -> 0.24897774308919907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [03:36<05:23, 53.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch4, Train loss: 0.2795338584110141, Acc: 0.8955512572533849, F1-Macro: 0.8948236889692586\n",
      "Fold3 Epoch/4, Val loss: 0.3872242383658886, Acc: 0.9147286821705426, F1-Macro: 0.9147081805613992\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [04:21<04:16, 51.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch5, Train loss: 0.25033129565417767, Acc: 0.9206963249516441, F1-Macro: 0.9204283960674053\n",
      "Fold3 Epoch/5, Val loss: 0.6213576570153236, Acc: 0.7674418604651163, F1-Macro: 0.7583666333666335\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [05:06<03:17, 49.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch6, Train loss: 0.30763318110257387, Acc: 0.8781431334622823, F1-Macro: 0.8777314378596714\n",
      "Fold3 Epoch/6, Val loss: 0.2716269325464964, Acc: 0.8914728682170543, F1-Macro: 0.891309581126625\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [05:50<02:23, 47.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch7, Train loss: 0.24667415395379066, Acc: 0.9148936170212766, F1-Macro: 0.914501774009261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [06:35<01:33, 46.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 Epoch/7, Val loss: 0.24950696201995015, Acc: 0.875968992248062, F1-Macro: 0.875901875901876\n",
      "Early stopping counter 4/10\n",
      "Fold3 /Epoch8, Train loss: 0.2319629960693419, Acc: 0.9148936170212766, F1-Macro: 0.914501774009261\n",
      "Fold3 Epoch/8, Val loss: 0.3465782403945923, Acc: 0.8682170542635659, F1-Macro: 0.8670667394071649\n",
      "Early stopping counter 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [07:20<00:46, 46.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch9, Train loss: 0.19092631433159113, Acc: 0.941972920696325, F1-Macro: 0.9416408295957377\n",
      "Fold3 Epoch/9, Val loss: 0.35731011629104614, Acc: 0.8914728682170543, F1-Macro: 0.891309581126625\n",
      "Early stopping counter 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [08:04<00:00, 48.47s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "Fold4 /Epoch0, Train loss: 0.19341284409165382, Acc: 0.9284332688588007, F1-Macro: 0.9283807512739009\n",
      "Fold4 Epoch/0, Val loss: 0.6682897321879864, Acc: 0.9069767441860465, F1-Macro: 0.9065217391304348\n",
      "Early stopping counter 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:44<06:42, 44.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 /Epoch1, Train loss: 0.1811527123209089, Acc: 0.941972920696325, F1-Macro: 0.9419240331905461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:30<06:00, 45.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Epoch/1, Val loss: 0.15087953757029027, Acc: 0.9457364341085271, F1-Macro: 0.9450896929157799\n",
      "Validation loss decreased 0.24897774308919907 -> 0.15087953757029027\n",
      "Fold4 /Epoch2, Train loss: 0.1339610288850963, Acc: 0.97678916827853, F1-Macro: 0.9767696132762184\n",
      "Fold4 Epoch/2, Val loss: 0.14846818055957556, Acc: 0.9534883720930233, F1-Macro: 0.9528508771929824\n",
      "Validation loss decreased 0.15087953757029027 -> 0.14846818055957556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:27<05:39, 48.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 /Epoch3, Train loss: 0.11380712478421628, Acc: 0.9748549323017408, F1-Macro: 0.9748172461210466\n",
      "Fold4 Epoch/3, Val loss: 0.6104681268334389, Acc: 0.9534883720930233, F1-Macro: 0.9526663405088063\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [03:24<05:06, 51.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 /Epoch4, Train loss: 0.1197222089394927, Acc: 0.9806576402321083, F1-Macro: 0.9806367041198503\n",
      "Fold4 Epoch/4, Val loss: 0.2664729878306389, Acc: 0.8992248062015504, F1-Macro: 0.8934629311987803\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [04:22<04:26, 53.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 /Epoch5, Train loss: 0.201831866055727, Acc: 0.9303675048355899, F1-Macro: 0.9301477211313276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [05:17<03:35, 53.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Epoch/5, Val loss: 0.15122418294777162, Acc: 0.9457364341085271, F1-Macro: 0.9446589446589446\n",
      "Early stopping counter 3/10\n",
      "Fold4 /Epoch6, Train loss: 0.1058063234668225, Acc: 0.9806576402321083, F1-Macro: 0.9806314811484744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [06:13<02:43, 54.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Epoch/6, Val loss: 0.23438867181539536, Acc: 0.9689922480620154, F1-Macro: 0.9684442270058709\n",
      "Early stopping counter 4/10\n",
      "Fold4 /Epoch7, Train loss: 0.09888093429617584, Acc: 0.9845261121856866, F1-Macro: 0.9845005396330495\n",
      "Fold4 Epoch/7, Val loss: 0.6997243268415332, Acc: 0.9457364341085271, F1-Macro: 0.9446589446589446\n",
      "Early stopping counter 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [07:13<01:52, 56.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 /Epoch8, Train loss: 0.07415435434086248, Acc: 0.9922630560928434, F1-Macro: 0.9922502698165248\n",
      "Fold4 Epoch/8, Val loss: 0.1632491541095078, Acc: 0.9457364341085271, F1-Macro: 0.9450896929157799\n",
      "Early stopping counter 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [08:09<00:56, 56.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 /Epoch9, Train loss: 0.05851603369228542, Acc: 0.9941972920696325, F1-Macro: 0.9941885952587031\n",
      "Fold4 Epoch/9, Val loss: 0.2153732469305396, Acc: 0.9224806201550387, F1-Macro: 0.9219128329297821\n",
      "Early stopping counter 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [09:06<00:00, 54.67s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5\n",
      "Fold5 /Epoch0, Train loss: 0.11007195455022156, Acc: 0.9748549323017408, F1-Macro: 0.974636300167934\n",
      "Fold5 Epoch/0, Val loss: 0.05267800623551011, Acc: 1.0, F1-Macro: 1.0\n",
      "Validation loss decreased 0.14846818055957556 -> 0.05267800623551011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:55<08:23, 55.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 /Epoch1, Train loss: 0.07656325737480074, Acc: 0.988394584139265, F1-Macro: 0.9882978723404255\n",
      "Fold5 Epoch/1, Val loss: 0.09321231860667467, Acc: 1.0, F1-Macro: 1.0\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:52<07:29, 56.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 /Epoch2, Train loss: 0.0644363296451047, Acc: 0.9903288201160542, F1-Macro: 0.9902447308338207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:48<06:33, 56.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 Epoch/2, Val loss: 0.08159416925991536, Acc: 0.9922480620155039, F1-Macro: 0.992218133558545\n",
      "Early stopping counter 2/10\n",
      "Fold5 /Epoch3, Train loss: 0.061602402944117785, Acc: 0.9941972920696325, F1-Macro: 0.9941468385002925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [03:46<05:39, 56.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 Epoch/3, Val loss: 0.04558650145190768, Acc: 1.0, F1-Macro: 1.0\n",
      "Validation loss decreased 0.05267800623551011 -> 0.04558650145190768\n",
      "Fold5 /Epoch4, Train loss: 0.05095005256589502, Acc: 0.9980657640232108, F1-Macro: 0.9980489461667642\n",
      "Fold5 Epoch/4, Val loss: 0.04753070790320635, Acc: 1.0, F1-Macro: 1.0\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [04:43<04:43, 56.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 /Epoch5, Train loss: 0.041018221992999315, Acc: 1.0, F1-Macro: 1.0\n",
      "Fold5 Epoch/5, Val loss: 0.07764315186068416, Acc: 0.9922480620155039, F1-Macro: 0.992218133558545\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [05:41<03:48, 57.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 /Epoch6, Train loss: 0.04281188180902973, Acc: 0.9980657640232108, F1-Macro: 0.9980503294075943\n",
      "Fold5 Epoch/6, Val loss: 0.22453930135816336, Acc: 0.9922480620155039, F1-Macro: 0.992218133558545\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [06:39<02:52, 57.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 /Epoch7, Train loss: 0.03201212710700929, Acc: 1.0, F1-Macro: 1.0\n",
      "Fold5 Epoch/7, Val loss: 0.05077476555015892, Acc: 1.0, F1-Macro: 1.0\n",
      "Early stopping counter 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [07:35<01:54, 57.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 /Epoch8, Train loss: 0.029848978156223893, Acc: 1.0, F1-Macro: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [08:31<00:56, 56.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 Epoch/8, Val loss: 0.05236455473641399, Acc: 0.9844961240310077, F1-Macro: 0.9843825665859565\n",
      "Early stopping counter 5/10\n",
      "Fold5 /Epoch9, Train loss: 0.02359281782992184, Acc: 1.0, F1-Macro: 1.0\n",
      "Fold5 Epoch/9, Val loss: 0.05082301894435659, Acc: 1.0, F1-Macro: 1.0\n",
      "Early stopping counter 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [09:28<00:00, 56.83s/it]\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "    \n",
    "\n",
    "    for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "\n",
    "        trainer.train_epoch(fold, train_loader, epoch_index)\n",
    "        trainer.validate_epoch(fold, test_loader, epoch_index)\n",
    "\n",
    "        # early_stopping check\n",
    "        early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "        if early_stopper.stop:\n",
    "            print('Early stopped')\n",
    "            break\n",
    "\n",
    "        if early_stopper.save_model:           \n",
    "            check_point = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            torch.save(check_point, 'best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
   "metadata": {},
   "source": [
    "### epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.7150068382422129, Acc: 0.5679862306368331, F1-Macro: 0.5596371553413597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:43<06:31, 43.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 1.0537893772125244, Acc: 0.6153846153846154, F1-Macro: 0.5905769715293524\n",
      "Epoch 1, Train loss: 0.6220975004964404, Acc: 0.6764199655765921, F1-Macro: 0.6764190069913497\n",
      "Epoch 1, Val loss: 0.8865877091884613, Acc: 0.5076923076923077, F1-Macro: 0.3627450980392157\n",
      "Validation loss decreased 1.0537893772125244 -> 0.8865877091884613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:26<05:47, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.5785027659601636, Acc: 0.7005163511187608, F1-Macro: 0.6983709273182956\n",
      "Epoch 2, Val loss: 0.5585557892918587, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Validation loss decreased 0.8865877091884613 -> 0.5585557892918587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:10<05:03, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.49541593260235256, Acc: 0.7728055077452668, F1-Macro: 0.7705975256646486\n",
      "Epoch 3, Val loss: 0.4888179078698158, Acc: 0.8615384615384616, F1-Macro: 0.8614072494669509\n",
      "Validation loss decreased 0.5585557892918587 -> 0.4888179078698158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [02:53<04:20, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.4270397300521533, Acc: 0.8158347676419966, F1-Macro: 0.8143476170424988\n",
      "Epoch 4, Val loss: 0.9447085410356522, Acc: 0.7692307692307693, F1-Macro: 0.767247553115302\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [03:36<03:36, 43.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.4104241347975201, Acc: 0.8450946643717728, F1-Macro: 0.8443193997856376\n",
      "Epoch 5, Val loss: 0.997687965631485, Acc: 0.8153846153846154, F1-Macro: 0.8099415204678363\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [04:18<02:51, 42.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.39116421507464516, Acc: 0.8296041308089501, F1-Macro: 0.8287926277157169\n",
      "Epoch 6, Val loss: 0.8743369281291962, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [05:01<02:08, 42.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.3476083038581742, Acc: 0.8657487091222031, F1-Macro: 0.8655730897009968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [05:43<01:25, 42.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val loss: 0.4742511548101902, Acc: 0.7692307692307693, F1-Macro: 0.7636363636363637\n",
      "Validation loss decreased 0.4888179078698158 -> 0.4742511548101902\n",
      "Epoch 8, Train loss: 0.352601816256841, Acc: 0.8605851979345955, F1-Macro: 0.8588727452656202\n",
      "Epoch 8, Val loss: 0.4510917328298092, Acc: 0.7846153846153846, F1-Macro: 0.7833333333333333\n",
      "Validation loss decreased 0.4742511548101902 -> 0.4510917328298092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [06:27<00:42, 42.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.33472725252310437, Acc: 0.8726333907056799, F1-Macro: 0.8720568979883347\n",
      "Epoch 9, Val loss: 0.44625740870833397, Acc: 0.7846153846153846, F1-Macro: 0.7841555977229602\n",
      "Validation loss decreased 0.4510917328298092 -> 0.44625740870833397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [07:09<00:00, 42.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# for epoch_index in enumerate(tqdm(range(EPOCHS)):\n",
    "\n",
    "#     trainer.train_epoch(train_dataloader, epoch_index)\n",
    "#     trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "#     # early_stopping check\n",
    "#     early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "#     if early_stopper.stop:\n",
    "#         print('Early stopped')\n",
    "#         break\n",
    "\n",
    "#     if early_stopper.save_model:\n",
    "#         check_point = {\n",
    "#             'model': model.state_dict(),\n",
    "#             'optimizer': optimizer.state_dict(),\n",
    "#             'scheduler': scheduler.state_dict()\n",
    "#         }\n",
    "#         torch.save(check_point, 'best.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53514a-e83f-4795-9589-640f26cc2993",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = 'best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ceab2318-ee3a-43c1-91bb-3a0b5138a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2478b8d5-c566-45fc-a44c-33d156a76ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f46bd06-5950-469b-a822-79ea7331b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_CNN(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 25, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=21025, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.7591e-01, 2.2409e-01],\n",
      "        [1.6266e-01, 8.3734e-01],\n",
      "        [7.1642e-01, 2.8358e-01],\n",
      "        [1.4535e-01, 8.5465e-01],\n",
      "        [9.5362e-01, 4.6380e-02],\n",
      "        [7.3817e-03, 9.9262e-01],\n",
      "        [7.8179e-01, 2.1821e-01],\n",
      "        [2.6471e-01, 7.3529e-01],\n",
      "        [9.9913e-01, 8.6669e-04],\n",
      "        [3.6969e-06, 1.0000e+00],\n",
      "        [4.9509e-01, 5.0491e-01],\n",
      "        [9.6981e-01, 3.0187e-02],\n",
      "        [1.9156e-01, 8.0844e-01],\n",
      "        [9.7726e-01, 2.2738e-02],\n",
      "        [9.9296e-01, 7.0404e-03],\n",
      "        [8.7383e-01, 1.2617e-01],\n",
      "        [2.1185e-01, 7.8815e-01],\n",
      "        [9.9801e-01, 1.9904e-03],\n",
      "        [5.5727e-01, 4.4273e-01],\n",
      "        [9.6909e-01, 3.0913e-02],\n",
      "        [9.7929e-01, 2.0709e-02],\n",
      "        [9.7453e-01, 2.5467e-02],\n",
      "        [5.7598e-01, 4.2402e-01],\n",
      "        [1.7959e-02, 9.8204e-01],\n",
      "        [9.8618e-01, 1.3823e-02],\n",
      "        [9.4867e-01, 5.1326e-02],\n",
      "        [9.9292e-01, 7.0764e-03],\n",
      "        [7.9816e-01, 2.0184e-01],\n",
      "        [4.8135e-04, 9.9952e-01],\n",
      "        [7.8308e-02, 9.2169e-01],\n",
      "        [7.8645e-01, 2.1355e-01],\n",
      "        [6.3370e-04, 9.9937e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.6303e-01, 1.3697e-01],\n",
      "        [7.5872e-01, 2.4128e-01],\n",
      "        [9.8008e-01, 1.9923e-02],\n",
      "        [5.2543e-01, 4.7457e-01],\n",
      "        [9.1676e-01, 8.3241e-02],\n",
      "        [1.0033e-02, 9.8997e-01],\n",
      "        [3.4319e-01, 6.5681e-01],\n",
      "        [1.3339e-02, 9.8666e-01],\n",
      "        [1.1144e-02, 9.8886e-01],\n",
      "        [2.5444e-01, 7.4556e-01],\n",
      "        [4.2031e-01, 5.7969e-01],\n",
      "        [5.6810e-02, 9.4319e-01],\n",
      "        [8.3454e-01, 1.6546e-01],\n",
      "        [7.5278e-02, 9.2472e-01],\n",
      "        [1.3374e-01, 8.6626e-01],\n",
      "        [9.9996e-01, 3.8708e-05],\n",
      "        [9.2072e-01, 7.9279e-02],\n",
      "        [6.7759e-01, 3.2241e-01],\n",
      "        [2.5856e-01, 7.4144e-01],\n",
      "        [4.7672e-03, 9.9523e-01],\n",
      "        [9.3674e-01, 6.3256e-02],\n",
      "        [8.9664e-01, 1.0336e-01],\n",
      "        [5.7039e-01, 4.2961e-01],\n",
      "        [6.3519e-01, 3.6481e-01],\n",
      "        [3.2164e-01, 6.7836e-01],\n",
      "        [1.1429e-01, 8.8571e-01],\n",
      "        [9.9852e-01, 1.4813e-03],\n",
      "        [2.2690e-01, 7.7310e-01],\n",
      "        [3.4123e-02, 9.6588e-01],\n",
      "        [9.7850e-01, 2.1498e-02],\n",
      "        [9.9895e-01, 1.0478e-03],\n",
      "        [9.9322e-01, 6.7756e-03]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1100e-03, 9.9789e-01],\n",
      "        [6.2854e-05, 9.9994e-01],\n",
      "        [1.7795e-01, 8.2205e-01],\n",
      "        [6.4894e-01, 3.5106e-01],\n",
      "        [1.0016e-02, 9.8998e-01],\n",
      "        [8.5132e-01, 1.4868e-01],\n",
      "        [9.5380e-01, 4.6204e-02],\n",
      "        [9.9356e-01, 6.4381e-03],\n",
      "        [9.9782e-01, 2.1850e-03],\n",
      "        [9.9661e-01, 3.3865e-03],\n",
      "        [2.5878e-03, 9.9741e-01],\n",
      "        [9.9994e-01, 6.3812e-05],\n",
      "        [9.9683e-01, 3.1712e-03],\n",
      "        [9.4897e-01, 5.1029e-02],\n",
      "        [4.4447e-01, 5.5553e-01],\n",
      "        [1.7530e-01, 8.2470e-01],\n",
      "        [4.2824e-03, 9.9572e-01],\n",
      "        [9.8016e-01, 1.9839e-02],\n",
      "        [8.2620e-01, 1.7380e-01],\n",
      "        [4.9183e-02, 9.5082e-01],\n",
      "        [6.7139e-01, 3.2861e-01],\n",
      "        [2.7075e-01, 7.2925e-01],\n",
      "        [1.6222e-01, 8.3778e-01],\n",
      "        [5.1828e-01, 4.8172e-01],\n",
      "        [7.1178e-01, 2.8822e-01],\n",
      "        [4.8744e-01, 5.1256e-01],\n",
      "        [9.4348e-01, 5.6516e-02],\n",
      "        [7.3775e-01, 2.6225e-01],\n",
      "        [7.7175e-01, 2.2825e-01],\n",
      "        [2.8542e-03, 9.9715e-01],\n",
      "        [9.9877e-01, 1.2308e-03],\n",
      "        [6.6614e-01, 3.3386e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0612, 0.9388],\n",
      "        [0.0448, 0.9552],\n",
      "        [0.1332, 0.8668],\n",
      "        [0.0373, 0.9627]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
   "metadata": {},
   "source": [
    "### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380e162-e63a-46b6-8700-8989a8a813d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d26da-7e0c-4098-bc1f-4c1e6ad9e2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3649d3-b49c-448e-86c0-8d45a7a9615e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b5456-d8a7-40b0-852e-a493282a08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690278dd-d257-4a5b-a638-a09d436d9df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
