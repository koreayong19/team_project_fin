{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
   "metadata": {},
   "source": [
    "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
    "- 이미지 binary 분류 과제\n",
    "- 담당: 이녕민M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4325d39-6344-4116-b343-df51696905ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt-get update && apt-get install -y python3-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "6f475804-13db-484c-a348-f01580e80a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# ! pip install mxnet\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import mxnet as mx\n",
    "import random\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
   "metadata": {},
   "source": [
    "## Set Arguments & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드(seed) 설정\n",
    "\n",
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65",
   "metadata": {},
   "source": [
    "# 데이터 디렉토리 구조\n",
    "\n",
    "data/  \n",
    "  \\_train/  \n",
    "    \\_0.png  \n",
    "    \\_1.png  \n",
    "    \\_...  \n",
    "  \\_test/  \n",
    "    \\_0.png  \n",
    "    \\_1.png  \n",
    "    \\_...  \n",
    "  \\_train.csv  \n",
    "  \\_sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= 'data'\n",
    "NUM_CLS = 2\n",
    "\n",
    "EPOCHS = 70\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0015\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "INPUT_SHAPE = 512 # 크게하는게 좋다고 함\n",
    "\n",
    "k = 5\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
   "metadata": {},
   "source": [
    "#### Train & Validation Set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04642777-c2e0-439b-9692-f6c571a86521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.8)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.8):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        # self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "        #                                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #                                      transforms.ToTensor(),\n",
    "        #                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        self.transform = albumentations.Compose([albumentations.Resize(512, 512), \n",
    "                                                 albumentations.RandomCrop(500, 500),\n",
    "                                                 albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "                                                 albumentations.VerticalFlip(),\n",
    "                                                 albumentations.ChannelShuffle(p=0.05),\n",
    "                                                 albumentations.RandomBrightnessContrast(p=0.5),\n",
    "                                                albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                albumentations.pytorch.transforms.ToTensorV2()])\n",
    "        \n",
    "        \n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        image = cv2.cvtColor(cvimg, cv2.COLOR_BGR2RGB)\n",
    "        trans_image = self.transform(image = image)\n",
    "        trans_image = trans_image['image']\n",
    "        \n",
    "        \n",
    "        # trans_image = self.transform(Image.fromarray(cvimg))\n",
    "        \n",
    "\n",
    "        return trans_image, data['COVID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0a9338-df41-442b-be8e-7faf93aaeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지를 구현, hide-and-seek구현 함수(사용x)\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n",
    "\n",
    "def hide_patch(img):\n",
    "    # get width and height of the image\n",
    "    s = img.shape\n",
    "    wd = s[0]\n",
    "    ht = s[1]\n",
    "\n",
    "    # possible grid size, 0 means no hiding\n",
    "    # grid_sizes=[0,16,32,44,56]\n",
    "    grid_sizes=[0,16,32,44,56]\n",
    "\n",
    "    # hiding probability\n",
    "    hide_prob = 0.5\n",
    " \n",
    "    # randomly choose one grid size\n",
    "    grid_size= grid_sizes[random.randint(0,len(grid_sizes)-1)]\n",
    "    # print(grid_size)\n",
    "    # hide the patches\n",
    "    # if(grid_size<>0):\n",
    "    if(grid_size!=0):\n",
    "         for x in range(0,wd,grid_size):\n",
    "             for y in range(0,ht,grid_size):\n",
    "                 x_end = min(wd, x+grid_size)  \n",
    "                 y_end = min(ht, y+grid_size)\n",
    "                 if(random.random() <=  hide_prob):\n",
    "                       img[x:x_end,y:y_end,:]=0\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class custom_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(custom_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        output = self.softmax(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99cb6193-5c8c-4330-9f2d-4bae23d27b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class resnet(nn.Module):\n",
    "    def __init__(self, numclasses):\n",
    "        super(resnet, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, numclasses)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_img):\n",
    "        x = self.model(input_img)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056905-1f77-4579-a260-07bb1056f6db",
   "metadata": {},
   "source": [
    "## Utils\n",
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            \n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train\n",
    "### 학습을 위한 객체 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 581 Val set samples: 65\n"
     ]
    }
   ],
   "source": [
    "# # Load dataset & dataloader\n",
    "# train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "# validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "913fb617-5910-4ead-982b-485ea231195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 516 Val set samples: 130\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader (ab)\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "\n",
    "dataset = ConcatDataset([train_dataset, validation_dataset])\n",
    "splits=KFold(n_splits=k,shuffle=True, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
   "metadata": {},
   "source": [
    "#### Load model and other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "# model = custom_CNN(NUM_CLS).to(DEVICE)\n",
    "model = resnet(NUM_CLS).to(DEVICE)\n",
    "\n",
    "# # Save Initial Model\n",
    "# torch.save(model.state_dict(), 'initial.pt')\n",
    "\n",
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = get_metric_fn\n",
    "\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
   "metadata": {},
   "source": [
    "### epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.7290288044346703, Acc: 0.5628227194492255, F1-Macro: 0.5625311262361563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 1/30 [00:43<21:02, 43.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.9351228773593903, Acc: 0.49230769230769234, F1-Macro: 0.32989690721649484\n",
      "Epoch 1, Train loss: 0.5783598290549384, Acc: 0.7590361445783133, F1-Macro: 0.7582562590646473\n",
      "Epoch 1, Val loss: 0.9273214936256409, Acc: 0.6307692307692307, F1-Macro: 0.6285714285714286\n",
      "Validation loss decreased 0.9351228773593903 -> 0.9273214936256409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 2/30 [01:27<20:26, 43.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.328860138853391, Acc: 0.9018932874354562, F1-Macro: 0.9012744265080714\n",
      "Epoch 2, Val loss: 1.0944306552410126, Acc: 0.7230769230769231, F1-Macro: 0.7198275862068966\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 3/30 [02:12<19:44, 43.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.09491647241844071, Acc: 0.9862306368330465, F1-Macro: 0.9861804861804861\n",
      "Epoch 3, Val loss: 0.6738913916051388, Acc: 0.7384615384615385, F1-Macro: 0.7362138935306756\n",
      "Validation loss decreased 0.9273214936256409 -> 0.6738913916051388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% 4/30 [02:55<18:54, 43.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.03496186766359541, Acc: 0.9948364888123924, F1-Macro: 0.9948118978095672\n",
      "Epoch 4, Val loss: 0.7430957239121199, Acc: 0.7692307692307693, F1-Macro: 0.7683535281539557\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% 5/30 [03:38<18:06, 43.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.03325988332896183, Acc: 0.9982788296041308, F1-Macro: 0.9982714352442751\n",
      "Epoch 5, Val loss: 1.1020513474941254, Acc: 0.7076923076923077, F1-Macro: 0.7006060606060607\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 6/30 [04:21<17:24, 43.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.09886101281477346, Acc: 0.9707401032702238, F1-Macro: 0.9705863959475517\n",
      "Epoch 6, Val loss: 0.6647143638692796, Acc: 0.7384615384615385, F1-Macro: 0.7321212121212122\n",
      "Validation loss decreased 0.6738913916051388 -> 0.6647143638692796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% 7/30 [05:04<16:36, 43.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.13452754521535504, Acc: 0.9845094664371773, F1-Macro: 0.9844201117318436\n",
      "Epoch 7, Val loss: 0.8683702635898953, Acc: 0.7076923076923077, F1-Macro: 0.6973780936045086\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 8/30 [05:49<16:04, 43.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 0.1495537774430381, Acc: 0.9535283993115319, F1-Macro: 0.9533492929683436\n",
      "Epoch 8, Val loss: 0.5791654512286186, Acc: 0.7384615384615385, F1-Macro: 0.7374673319078165\n",
      "Validation loss decreased 0.6647143638692796 -> 0.5791654512286186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 9/30 [06:33<15:20, 43.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.03626256878487766, Acc: 0.9931153184165232, F1-Macro: 0.9930872834570722\n",
      "Epoch 9, Val loss: 0.8948061764240265, Acc: 0.676923076923077, F1-Macro: 0.656084656084656\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 10/30 [07:16<14:32, 43.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 0.014182086089729436, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 10, Val loss: 0.6085092797875404, Acc: 0.7538461538461538, F1-Macro: 0.7509578544061302\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% 11/30 [07:56<13:29, 42.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 0.003650686852375252, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 11, Val loss: 0.6245921514928341, Acc: 0.7692307692307693, F1-Macro: 0.767247553115302\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 12/30 [08:40<12:54, 43.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 0.010709233258643912, Acc: 1.0, F1-Macro: 1.0\n",
      "Epoch 12, Val loss: 1.0297811329364777, Acc: 0.7538461538461538, F1-Macro: 0.7509578544061302\n",
      "Early stopping counter 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 13/30 [09:23<12:12, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 0.09652600886248466, Acc: 0.9948364888123924, F1-Macro: 0.9948165881075937\n",
      "Epoch 13, Val loss: 2.568748414516449, Acc: 0.6461538461538462, F1-Macro: 0.6233308138070042\n",
      "Early stopping counter 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% 14/30 [10:07<11:32, 43.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 0.3886534674093127, Acc: 0.9345955249569707, F1-Macro: 0.9343573093573092\n",
      "Epoch 14, Val loss: 1.20190768991597, Acc: 0.7230769230769231, F1-Macro: 0.7075\n",
      "Early stopping counter 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 15/30 [10:50<10:48, 43.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 0.4394403100013733, Acc: 0.8364888123924269, F1-Macro: 0.8346053692200277\n",
      "Epoch 15, Val loss: 0.7853747298941016, Acc: 0.6615384615384615, F1-Macro: 0.6549227799227799\n",
      "Early stopping counter 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 16/30 [11:34<10:06, 43.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 0.39370400624142754, Acc: 0.8485370051635112, F1-Macro: 0.8466172270621835\n",
      "Epoch 16, Val loss: 1.6119196712970734, Acc: 0.676923076923077, F1-Macro: 0.656084656084656\n",
      "Early stopping counter 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% 17/30 [12:17<09:22, 43.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 0.34664354307783973, Acc: 0.8537005163511188, F1-Macro: 0.8526089279265567\n",
      "Epoch 17, Val loss: 0.8143983586342074, Acc: 0.676923076923077, F1-Macro: 0.6612062546537603\n",
      "Early stopping counter 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 18/30 [13:00<08:39, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 0.3429244988494449, Acc: 0.8691910499139415, F1-Macro: 0.8683293971707341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 18/30 [13:42<09:08, 45.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Val loss: 2.4883471727371216, Acc: 0.7230769230769231, F1-Macro: 0.7176640926640927\n",
      "Early stopping counter 10/10\n",
      "Early stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "    trainer.train_epoch(train_dataloader, epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if early_stopper.save_model:\n",
    "        check_point = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        torch.save(check_point, 'best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f678cd-5966-4468-a441-202715ec22e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 0, Train loss: 0.7677584774792194, Acc: 0.5406976744186046, F1-Macro: 0.35475156573997374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 1/70 [00:33<38:54, 33.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.8730338960886002, Acc: 0.49230769230769234, F1-Macro: 0.32989690721649484\n",
      "Epoch 1, Train loss: 0.7480146810412407, Acc: 0.5542635658914729, F1-Macro: 0.4735908308642194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 2/70 [01:07<38:20, 33.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val loss: 1.097356379032135, Acc: 0.49230769230769234, F1-Macro: 0.32989690721649484\n",
      "Early stopping counter 1/15\n",
      "Epoch 2, Train loss: 0.7116210833191872, Acc: 0.6027131782945736, F1-Macro: 0.5855519117975481\n",
      "Epoch 2, Val loss: 0.7908166348934174, Acc: 0.6153846153846154, F1-Macro: 0.6060606060606061\n",
      "Validation loss decreased 0.8730338960886002 -> 0.7908166348934174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 3/70 [01:44<38:38, 34.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6866402477025986, Acc: 0.6298449612403101, F1-Macro: 0.6156986605837281\n",
      "Epoch 3, Val loss: 0.8076637610793114, Acc: 0.5615384615384615, F1-Macro: 0.5351025785808394\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 4/70 [02:19<38:18, 34.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.6769662387669086, Acc: 0.6414728682170543, F1-Macro: 0.6398157196705292\n",
      "Epoch 4, Val loss: 0.9774603992700577, Acc: 0.4846153846153846, F1-Macro: 0.32642487046632124\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 5/70 [02:55<37:59, 35.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.6650932468473911, Acc: 0.6434108527131783, F1-Macro: 0.6200294550810015\n",
      "Epoch 5, Val loss: 1.3980063274502754, Acc: 0.5076923076923077, F1-Macro: 0.39552455681487936\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9% 6/70 [03:30<37:34, 35.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.6709012165665627, Acc: 0.6744186046511628, F1-Macro: 0.673825685173758\n",
      "Epoch 6, Val loss: 0.7742494344711304, Acc: 0.5846153846153846, F1-Macro: 0.5541158536585367\n",
      "Validation loss decreased 0.7908166348934174 -> 0.7742494344711304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 7/70 [04:06<37:11, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.6113595813512802, Acc: 0.689922480620155, F1-Macro: 0.6844422700587085\n",
      "Epoch 7, Val loss: 0.8815345913171768, Acc: 0.7230769230769231, F1-Macro: 0.722024233784747\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% 8/70 [04:42<36:38, 35.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 0.5740932803601027, Acc: 0.7461240310077519, F1-Macro: 0.744950590685618\n",
      "Epoch 8, Val loss: 1.8229484260082245, Acc: 0.5076923076923077, F1-Macro: 0.3627450980392157\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% 9/70 [05:17<36:07, 35.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.5938751883804798, Acc: 0.7267441860465116, F1-Macro: 0.7240484724355691\n",
      "Epoch 9, Val loss: 0.7152697294950485, Acc: 0.7230769230769231, F1-Macro: 0.7224857685009487\n",
      "Validation loss decreased 0.7742494344711304 -> 0.7152697294950485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 10/70 [05:53<35:41, 35.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 0.5282666869461536, Acc: 0.7596899224806202, F1-Macro: 0.7583795296285667\n",
      "Epoch 10, Val loss: 1.6809886991977692, Acc: 0.5153846153846153, F1-Macro: 0.36663831103549605\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 11/70 [06:29<35:13, 35.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 0.566200340166688, Acc: 0.748062015503876, F1-Macro: 0.7456740320599342\n",
      "Epoch 11, Val loss: 0.8048500753939152, Acc: 0.6692307692307692, F1-Macro: 0.6492879101574753\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% 12/70 [07:05<34:28, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 0.5936199426651001, Acc: 0.7364341085271318, F1-Macro: 0.7341334788143299\n",
      "Epoch 12, Val loss: 0.8145216442644596, Acc: 0.6, F1-Macro: 0.5305555555555556\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19% 13/70 [07:40<33:46, 35.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 0.5149604938924313, Acc: 0.7596899224806202, F1-Macro: 0.755442759295499\n",
      "Epoch 13, Val loss: 1.2341892719268799, Acc: 0.5923076923076923, F1-Macro: 0.5310053774419713\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 14/70 [08:16<33:10, 35.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 0.511585246771574, Acc: 0.7461240310077519, F1-Macro: 0.7422823090736483\n",
      "Epoch 14, Val loss: 0.8063863515853882, Acc: 0.6230769230769231, F1-Macro: 0.5814442473224258\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21% 15/70 [08:51<32:33, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 0.4634110555052757, Acc: 0.7926356589147286, F1-Macro: 0.7909008623464762\n",
      "Epoch 15, Val loss: 9.33148717880249, Acc: 0.5384615384615384, F1-Macro: 0.4333042720139495\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% 16/70 [09:26<31:54, 35.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 0.5600420013070107, Acc: 0.7364341085271318, F1-Macro: 0.7332927941623595\n",
      "Epoch 16, Val loss: 0.6948214024305344, Acc: 0.6538461538461539, F1-Macro: 0.649175412293853\n",
      "Validation loss decreased 0.7152697294950485 -> 0.6948214024305344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 17/70 [10:02<31:16, 35.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 0.5090223830193281, Acc: 0.7848837209302325, F1-Macro: 0.7840002715269999\n",
      "Epoch 17, Val loss: 1.087774008512497, Acc: 0.6538461538461539, F1-Macro: 0.6405529953917051\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% 18/70 [10:38<30:49, 35.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 0.44964600913226604, Acc: 0.7926356589147286, F1-Macro: 0.7915639499107168\n",
      "Epoch 18, Val loss: 0.71430454403162, Acc: 0.676923076923077, F1-Macro: 0.656084656084656\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 19/70 [11:13<30:18, 35.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train loss: 0.47146063577383757, Acc: 0.810077519379845, F1-Macro: 0.8097917669715937\n",
      "Epoch 19, Val loss: 0.8112664744257927, Acc: 0.6615384615384615, F1-Macro: 0.6366869918699187\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29% 20/70 [11:49<29:38, 35.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train loss: 0.45815877243876457, Acc: 0.7984496124031008, F1-Macro: 0.7954971571422038\n",
      "Epoch 20, Val loss: 0.7609854191541672, Acc: 0.6846153846153846, F1-Macro: 0.6628929226487887\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 21/70 [12:26<29:23, 35.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train loss: 0.44261438213288784, Acc: 0.8081395348837209, F1-Macro: 0.8054202296836612\n",
      "Epoch 21, Val loss: 0.9651745110750198, Acc: 0.7, F1-Macro: 0.6919618445835105\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31% 22/70 [13:01<28:43, 35.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train loss: 0.44665912725031376, Acc: 0.8081395348837209, F1-Macro: 0.807351593524081\n",
      "Epoch 22, Val loss: 1.1270202547311783, Acc: 0.5846153846153846, F1-Macro: 0.5362050739957717\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 23/70 [13:37<28:01, 35.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train loss: 0.34582843724638224, Acc: 0.8546511627906976, F1-Macro: 0.8532172725721113\n",
      "Epoch 23, Val loss: 0.9875669330358505, Acc: 0.7, F1-Macro: 0.688479262672811\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% 24/70 [14:12<27:19, 35.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train loss: 0.38885578885674477, Acc: 0.8546511627906976, F1-Macro: 0.8543091732516159\n",
      "Epoch 24, Val loss: 1.014338195323944, Acc: 0.6615384615384615, F1-Macro: 0.6334273263265828\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 25/70 [14:48<26:41, 35.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train loss: 0.4102446921169758, Acc: 0.8391472868217055, F1-Macro: 0.8362186657488672\n",
      "Epoch 25, Val loss: 0.8491911962628365, Acc: 0.7230769230769231, F1-Macro: 0.7149122807017544\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% 26/70 [15:23<26:03, 35.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train loss: 0.4205788541585207, Acc: 0.8178294573643411, F1-Macro: 0.8172115949893727\n",
      "Epoch 26, Val loss: 1.5176873803138733, Acc: 0.6461538461538462, F1-Macro: 0.6003742314889067\n",
      "Early stopping counter 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39% 27/70 [15:59<25:33, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train loss: 0.37916284892708063, Acc: 0.8546511627906976, F1-Macro: 0.8536347373556676\n",
      "Epoch 27, Val loss: 0.6288591015618294, Acc: 0.7538461538461538, F1-Macro: 0.7435897435897436\n",
      "Validation loss decreased 0.6948214024305344 -> 0.6288591015618294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 28/70 [16:35<25:01, 35.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train loss: 0.3240116210654378, Acc: 0.8643410852713178, F1-Macro: 0.8624817251461988\n",
      "Epoch 28, Val loss: 1.5227535665035248, Acc: 0.5923076923076923, F1-Macro: 0.5247948134354093\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41% 29/70 [17:11<24:28, 35.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train loss: 0.3413347080349922, Acc: 0.8410852713178295, F1-Macro: 0.8406159594985536\n",
      "Epoch 29, Val loss: 0.6837892644107342, Acc: 0.7, F1-Macro: 0.695952023988006\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 30/70 [17:47<23:59, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train loss: 0.30387797579169273, Acc: 0.8856589147286822, F1-Macro: 0.8852447275674249\n",
      "Epoch 30, Val loss: 0.7887697219848633, Acc: 0.6923076923076923, F1-Macro: 0.675\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44% 31/70 [18:23<23:23, 36.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train loss: 0.31148590706288815, Acc: 0.8798449612403101, F1-Macro: 0.8787961447535915\n",
      "Epoch 31, Val loss: 0.5474829589948058, Acc: 0.7692307692307693, F1-Macro: 0.7692307692307692\n",
      "Validation loss decreased 0.6288591015618294 -> 0.5474829589948058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46% 32/70 [18:59<22:45, 35.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train loss: 0.27720319386571646, Acc: 0.8914728682170543, F1-Macro: 0.890881077896772\n",
      "Epoch 32, Val loss: 0.6921755447983742, Acc: 0.6923076923076923, F1-Macro: 0.6920161099265577\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% 33/70 [19:36<22:20, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train loss: 0.2648963490501046, Acc: 0.9089147286821705, F1-Macro: 0.908493723375756\n",
      "Epoch 33, Val loss: 0.615870475769043, Acc: 0.7615384615384615, F1-Macro: 0.7611851851851852\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% 34/70 [20:12<21:36, 36.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train loss: 0.3021659515798092, Acc: 0.875968992248062, F1-Macro: 0.8755483199927645\n",
      "Epoch 34, Val loss: 0.7492668586783111, Acc: 0.6692307692307692, F1-Macro: 0.6519085870851236\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 35/70 [20:48<21:04, 36.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train loss: 0.3016284853219986, Acc: 0.8934108527131783, F1-Macro: 0.8922743474019442\n",
      "Epoch 35, Val loss: 1.1958682835102081, Acc: 0.6384615384615384, F1-Macro: 0.6065932650827378\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51% 36/70 [21:25<20:33, 36.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train loss: 0.2236905642785132, Acc: 0.9127906976744186, F1-Macro: 0.9122366058773506\n",
      "Epoch 36, Val loss: 0.6579155176877975, Acc: 0.7461538461538462, F1-Macro: 0.742728635682159\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 37/70 [22:01<19:56, 36.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train loss: 0.24545689998194575, Acc: 0.9147286821705426, F1-Macro: 0.914213167281301\n",
      "Epoch 37, Val loss: 0.8173917979001999, Acc: 0.7307692307692307, F1-Macro: 0.7260851243152129\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54% 38/70 [22:37<19:15, 36.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train loss: 0.2809248035773635, Acc: 0.8992248062015504, F1-Macro: 0.8984175058681001\n",
      "Epoch 38, Val loss: 0.8160572499036789, Acc: 0.7307692307692307, F1-Macro: 0.7248926779128122\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 39/70 [23:12<18:35, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train loss: 0.28325932286679745, Acc: 0.8914728682170543, F1-Macro: 0.8902711323763955\n",
      "Epoch 39, Val loss: 0.6522097066044807, Acc: 0.7846153846153846, F1-Macro: 0.7793939393939393\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% 40/70 [23:48<17:55, 35.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train loss: 0.2080770917236805, Acc: 0.9244186046511628, F1-Macro: 0.9241082035094865\n",
      "Epoch 40, Val loss: 0.6892850250005722, Acc: 0.7769230769230769, F1-Macro: 0.7746697746697746\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59% 41/70 [24:23<17:16, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Train loss: 0.19669010932557285, Acc: 0.9244186046511628, F1-Macro: 0.9240279817431585\n",
      "Epoch 41, Val loss: 0.8646175556350499, Acc: 0.7307692307692307, F1-Macro: 0.7220695131635209\n",
      "Early stopping counter 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 42/70 [24:59<16:39, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Train loss: 0.15084246243350208, Acc: 0.9496124031007752, F1-Macro: 0.9492763486230207\n",
      "Epoch 42, Val loss: 0.5089672738686204, Acc: 0.7769230769230769, F1-Macro: 0.776909876324043\n",
      "Validation loss decreased 0.5474829589948058 -> 0.5089672738686204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61% 43/70 [25:35<16:07, 35.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Train loss: 0.1853489524219185, Acc: 0.9186046511627907, F1-Macro: 0.9182497170878914\n",
      "Epoch 43, Val loss: 0.6562609486281872, Acc: 0.7692307692307693, F1-Macro: 0.7678571428571428\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63% 44/70 [26:12<15:37, 36.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Train loss: 0.18939897138625383, Acc: 0.9302325581395349, F1-Macro: 0.9298521215050677\n",
      "Epoch 44, Val loss: 0.5878569260239601, Acc: 0.7769230769230769, F1-Macro: 0.7765925925925927\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64% 45/70 [26:48<15:00, 36.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Train loss: 0.1564100938849151, Acc: 0.9554263565891473, F1-Macro: 0.9551702646042268\n",
      "Epoch 45, Val loss: 1.4280924201011658, Acc: 0.6538461538461539, F1-Macro: 0.635718288810013\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66% 46/70 [27:24<14:27, 36.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Train loss: 0.1397749709431082, Acc: 0.9554263565891473, F1-Macro: 0.9551959892331447\n",
      "Epoch 46, Val loss: 0.8004999458789825, Acc: 0.7846153846153846, F1-Macro: 0.7846153846153846\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% 47/70 [28:00<13:51, 36.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Train loss: 0.16994855378288776, Acc: 0.9321705426356589, F1-Macro: 0.9316507147155331\n",
      "Epoch 47, Val loss: 0.8110779821872711, Acc: 0.8, F1-Macro: 0.799573055028463\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69% 48/70 [28:36<13:11, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Train loss: 0.1719190018484369, Acc: 0.9302325581395349, F1-Macro: 0.9298913043478261\n",
      "Epoch 48, Val loss: 0.7416310124099255, Acc: 0.7307692307692307, F1-Macro: 0.7220695131635209\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 49/70 [29:11<12:31, 35.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Train loss: 0.13491142890416086, Acc: 0.936046511627907, F1-Macro: 0.9356790753017168\n",
      "Epoch 49, Val loss: 2.1358882635831833, Acc: 0.676923076923077, F1-Macro: 0.6532012195121952\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71% 50/70 [29:47<11:54, 35.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Train loss: 0.13949614157900214, Acc: 0.9437984496124031, F1-Macro: 0.9433677350500129\n",
      "Epoch 50, Val loss: 0.6275166997220367, Acc: 0.7846153846153846, F1-Macro: 0.7837966262770254\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73% 51/70 [30:23<11:24, 36.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Train loss: 0.20362933375872672, Acc: 0.9457364341085271, F1-Macro: 0.9453017339289771\n",
      "Epoch 51, Val loss: 0.748149074614048, Acc: 0.7923076923076923, F1-Macro: 0.7922954020947985\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% 52/70 [30:59<10:46, 35.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Train loss: 0.11278657079674304, Acc: 0.9670542635658915, F1-Macro: 0.9669019850508054\n",
      "Epoch 52, Val loss: 0.7689327523112297, Acc: 0.7538461538461538, F1-Macro: 0.7517307233229886\n",
      "Early stopping counter 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76% 53/70 [31:35<10:10, 35.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Train loss: 0.14419211354106665, Acc: 0.9476744186046512, F1-Macro: 0.9473737888832228\n",
      "Epoch 53, Val loss: 0.7128359819180332, Acc: 0.7692307692307693, F1-Macro: 0.767247553115302\n",
      "Early stopping counter 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% 54/70 [32:12<09:42, 36.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Train loss: 0.10516359121538699, Acc: 0.9709302325581395, F1-Macro: 0.9707958691624753\n",
      "Epoch 54, Val loss: 0.5617901952937245, Acc: 0.7692307692307693, F1-Macro: 0.7692307692307692\n",
      "Early stopping counter 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79% 55/70 [32:48<09:02, 36.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Train loss: 0.1573919989168644, Acc: 0.9534883720930233, F1-Macro: 0.9533088013512698\n",
      "Epoch 55, Val loss: 0.7529153749346733, Acc: 0.7769230769230769, F1-Macro: 0.7762744050798172\n",
      "Early stopping counter 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 56/70 [33:23<08:22, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Train loss: 0.16175608651246876, Acc: 0.9476744186046512, F1-Macro: 0.9473737888832228\n",
      "Epoch 56, Val loss: 0.6890469906502403, Acc: 0.7692307692307693, F1-Macro: 0.767247553115302\n",
      "Early stopping counter 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% 57/70 [33:59<07:43, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Train loss: 0.1730131865479052, Acc: 0.9709302325581395, F1-Macro: 0.9707269474711335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81% 57/70 [34:32<07:52, 36.37s/it]\n",
      "  0% 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Val loss: 0.6315476468298584, Acc: 0.7384615384615385, F1-Macro: 0.7384615384615384\n",
      "Early stopping counter 15/15\n",
      "Early stopped\n",
      "Fold 2\n",
      "Epoch 0, Train loss: 0.10616354993544519, Acc: 0.9709302325581395, F1-Macro: 0.9707074491637999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/70 [00:33<?, ?it/s]\n",
      "  0% 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.5859977398067713, Acc: 0.7692307692307693, F1-Macro: 0.7692307692307692\n",
      "Early stopping counter 16/15\n",
      "Early stopped\n",
      "Fold 3\n",
      "Epoch 0, Train loss: 0.09404243913013488, Acc: 0.9728682170542635, F1-Macro: 0.972687264643165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/70 [00:33<?, ?it/s]\n",
      "  0% 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.6230882676318288, Acc: 0.7692307692307693, F1-Macro: 0.7683535281539557\n",
      "Early stopping counter 17/15\n",
      "Early stopped\n",
      "Fold 4\n",
      "Epoch 0, Train loss: 0.10053127305582166, Acc: 0.9767441860465116, F1-Macro: 0.9765738498789346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/70 [00:33<?, ?it/s]\n",
      "  0% 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.6111526479944587, Acc: 0.7615384615384615, F1-Macro: 0.7611851851851852\n",
      "Early stopping counter 18/15\n",
      "Early stopped\n",
      "Fold 5\n",
      "Epoch 0, Train loss: 0.14284145284909755, Acc: 0.9728682170542635, F1-Macro: 0.9726313875250046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/70 [00:33<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.7113735836246633, Acc: 0.7846153846153846, F1-Macro: 0.7827643829076152\n",
      "Early stopping counter 19/15\n",
      "Early stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "    \n",
    "\n",
    "    for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "        trainer.train_epoch(train_dataloader, epoch_index)\n",
    "        trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "        # early_stopping check\n",
    "        early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "        if early_stopper.stop:\n",
    "            print('Early stopped')\n",
    "            break\n",
    "\n",
    "        if early_stopper.save_model:\n",
    "            check_point = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            torch.save(check_point, 'best.pt2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53514a-e83f-4795-9589-640f26cc2993",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = 'best.pt2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        # self.transform = albumentations.Compose([albumentations.Resize(512, 512), \n",
    "        #                                          albumentations.RandomCrop(500, 500),\n",
    "        #                                          albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "        #                                          albumentations.VerticalFlip(),\n",
    "        #                                         albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        #                                         albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        \n",
    "\n",
    "        # Preprocessing images\n",
    "        # image = cv2.cvtColor(cvimg, cv2.COLOR_BGR2RGB)\n",
    "        # trans_image = self.transform(image = image)\n",
    "        # trans_image = trans_image['image']\n",
    "        \n",
    "        \n",
    "        # trans_image = self.transform(Image.fromarray(cvimg))\n",
    "        \n",
    "\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b99b57b3-dea8-4dc4-992a-4c21310956ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.4096e-01, 5.9036e-02],\n",
      "        [9.1945e-01, 8.0553e-02],\n",
      "        [8.1609e-01, 1.8391e-01],\n",
      "        [2.6348e-03, 9.9737e-01],\n",
      "        [9.9855e-01, 1.4512e-03],\n",
      "        [1.0331e-03, 9.9897e-01],\n",
      "        [9.8606e-02, 9.0139e-01],\n",
      "        [1.0524e-02, 9.8948e-01],\n",
      "        [9.9994e-01, 6.0273e-05],\n",
      "        [8.3075e-02, 9.1693e-01],\n",
      "        [9.9941e-01, 5.8756e-04],\n",
      "        [9.9971e-01, 2.8627e-04],\n",
      "        [9.9904e-01, 9.5859e-04],\n",
      "        [9.9570e-01, 4.3049e-03],\n",
      "        [7.4064e-01, 2.5936e-01],\n",
      "        [9.9524e-01, 4.7590e-03],\n",
      "        [1.5276e-01, 8.4724e-01],\n",
      "        [9.9585e-01, 4.1526e-03],\n",
      "        [9.8847e-01, 1.1532e-02],\n",
      "        [8.9007e-01, 1.0993e-01],\n",
      "        [9.8180e-01, 1.8204e-02],\n",
      "        [9.9500e-01, 4.9987e-03],\n",
      "        [7.9554e-01, 2.0446e-01],\n",
      "        [9.9309e-01, 6.9100e-03],\n",
      "        [2.5804e-04, 9.9974e-01],\n",
      "        [9.7677e-01, 2.3230e-02],\n",
      "        [9.3526e-01, 6.4744e-02],\n",
      "        [9.8385e-01, 1.6152e-02],\n",
      "        [3.9198e-02, 9.6080e-01],\n",
      "        [5.6988e-04, 9.9943e-01],\n",
      "        [3.1706e-01, 6.8294e-01],\n",
      "        [3.8787e-01, 6.1213e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:06,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.2660e-03, 9.9473e-01],\n",
      "        [9.4359e-01, 5.6411e-02],\n",
      "        [6.4614e-01, 3.5386e-01],\n",
      "        [7.2441e-01, 2.7559e-01],\n",
      "        [7.0054e-01, 2.9946e-01],\n",
      "        [8.2167e-01, 1.7833e-01],\n",
      "        [4.2641e-03, 9.9574e-01],\n",
      "        [2.7088e-01, 7.2912e-01],\n",
      "        [4.3901e-03, 9.9561e-01],\n",
      "        [8.4197e-01, 1.5803e-01],\n",
      "        [9.8581e-01, 1.4190e-02],\n",
      "        [5.2318e-02, 9.4768e-01],\n",
      "        [9.2060e-02, 9.0794e-01],\n",
      "        [6.0380e-02, 9.3962e-01],\n",
      "        [9.9782e-01, 2.1756e-03],\n",
      "        [9.4623e-01, 5.3766e-02],\n",
      "        [6.7080e-01, 3.2920e-01],\n",
      "        [9.5971e-01, 4.0293e-02],\n",
      "        [4.3211e-03, 9.9568e-01],\n",
      "        [6.7904e-02, 9.3210e-01],\n",
      "        [8.5851e-01, 1.4149e-01],\n",
      "        [9.9795e-01, 2.0544e-03],\n",
      "        [9.6821e-01, 3.1787e-02],\n",
      "        [4.9841e-02, 9.5016e-01],\n",
      "        [8.2435e-01, 1.7565e-01],\n",
      "        [1.1276e-04, 9.9989e-01],\n",
      "        [9.9927e-01, 7.3299e-04],\n",
      "        [3.9945e-01, 6.0055e-01],\n",
      "        [2.1006e-01, 7.8994e-01],\n",
      "        [9.9860e-01, 1.4049e-03],\n",
      "        [9.9913e-01, 8.6821e-04],\n",
      "        [9.8509e-01, 1.4906e-02]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1291e-02, 9.7871e-01],\n",
      "        [1.4958e-03, 9.9850e-01],\n",
      "        [1.2360e-03, 9.9876e-01],\n",
      "        [9.3833e-01, 6.1667e-02],\n",
      "        [1.8011e-01, 8.1989e-01],\n",
      "        [9.8564e-01, 1.4362e-02],\n",
      "        [9.9903e-01, 9.7405e-04],\n",
      "        [9.1361e-01, 8.6395e-02],\n",
      "        [8.8030e-01, 1.1970e-01],\n",
      "        [9.8445e-01, 1.5553e-02],\n",
      "        [6.9984e-04, 9.9930e-01],\n",
      "        [9.9909e-01, 9.0992e-04],\n",
      "        [9.7837e-01, 2.1628e-02],\n",
      "        [9.9327e-01, 6.7271e-03],\n",
      "        [3.5443e-01, 6.4557e-01],\n",
      "        [8.8964e-03, 9.9110e-01],\n",
      "        [5.2841e-04, 9.9947e-01],\n",
      "        [5.9157e-01, 4.0843e-01],\n",
      "        [7.4577e-01, 2.5423e-01],\n",
      "        [4.3731e-01, 5.6269e-01],\n",
      "        [1.6254e-01, 8.3746e-01],\n",
      "        [1.8795e-01, 8.1205e-01],\n",
      "        [9.8936e-01, 1.0637e-02],\n",
      "        [3.8902e-03, 9.9611e-01],\n",
      "        [9.9587e-01, 4.1321e-03],\n",
      "        [9.5802e-02, 9.0420e-01],\n",
      "        [9.3838e-01, 6.1619e-02],\n",
      "        [9.9863e-01, 1.3662e-03],\n",
      "        [1.0582e-02, 9.8942e-01],\n",
      "        [3.2156e-04, 9.9968e-01],\n",
      "        [9.9963e-01, 3.7299e-04],\n",
      "        [7.5342e-01, 2.4658e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:09,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0070, 0.9930],\n",
      "        [0.3934, 0.6066],\n",
      "        [0.1257, 0.8743],\n",
      "        [0.0013, 0.9987]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "\n",
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
   "metadata": {},
   "source": [
    "### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('prediction3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
