{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
   "metadata": {},
   "source": [
    "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
    "- 이미지 binary 분류 과제\n",
    "- 담당: 이녕민M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4325d39-6344-4116-b343-df51696905ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \n",
      "Get:10 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2564 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]   \n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3002 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1468 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [783 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2247 kB]\n",
      "Fetched 10.3 MB in 4s (2508 kB/s)                           \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python3-opencv is already the newest version (3.2.0+dfsg-4ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 78 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y python3-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c541d56e-7985-49f3-99fe-25378f084196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f475804-13db-484c-a348-f01580e80a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
   "metadata": {},
   "source": [
    "## Set Arguments & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드(seed) 설정\n",
    "\n",
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= 'data'\n",
    "NUM_CLS = 2\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "INPUT_SHAPE = 128\n",
    "\n",
    "####\n",
    "k = 5\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train & Validation Set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04642777-c2e0-439b-9692-f6c571a86521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.8)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.8):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['COVID']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# class custom_CNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(custom_CNN, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "        \n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
    "        \n",
    "#         self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
    "#         self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
    "#         x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
    "        \n",
    "#         x = torch.flatten(x,1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        \n",
    "#         output = self.softmax(x)\n",
    "        \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1553326-e61b-4969-bdea-537d3a429a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "\n",
    "# class efficientnet_b0(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(efficientnet_b0, self).__init__()\n",
    "#         self.model = models.efficientnet_b0(pretrained=False)\n",
    "#         self.model.classifier = nn.Sequential(\n",
    "#             nn.Dropout(p=0.2, inplace=True),\n",
    "#             nn.Linear(1280, num_classes),\n",
    "#         )\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_img):\n",
    "#         x = self.model(input_img)\n",
    "#         x = self.softmax(x)\n",
    "#         return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c5ee5d-f61b-4e7e-a9e8-a9d907943cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "\n",
    "# class densenet161(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(densenet161, self).__init__()\n",
    "#         self.model = models.densenet161(pretrained=False)\n",
    "#         self.model.classifier = nn.Linear(in_features=2208, out_features=num_classes, bias=True)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_img):\n",
    "#         x = self.model(input_img)\n",
    "#         x = self.softmax(x)\n",
    "#         return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b2aeb88-1e5e-4396-800c-ad40d5134647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class densenet201(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(densenet201, self).__init__()\n",
    "        self.model = models.densenet201(pretrained=False)\n",
    "        self.model.classifier = nn.Linear(in_features=1920, out_features=num_classes, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        x = self.model(input_img)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056905-1f77-4579-a260-07bb1056f6db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utils\n",
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, fold, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            \n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "            \n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Fold{fold +1} /Epoch{epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, fold, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Fold{fold + 1} Epoch/{epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train\n",
    "### 학습을 위한 객체 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 516 Val set samples: 130\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "###\n",
    "dataset = ConcatDataset([train_dataset, validation_dataset])\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "####\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b74ea6-cbdf-4ade-8350-20c3dcbbce9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in splits.split(np.arange(len(dataset))):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
   "metadata": {},
   "source": [
    "#### Load model and other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = densenet201(NUM_CLS).to(DEVICE)\n",
    "\n",
    "# # Save Initial Model\n",
    "# torch.save(model.state_dict(), 'initial.pt')\n",
    "\n",
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(dataset))\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = get_metric_fn\n",
    "\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc632533-0e5e-4d29-94ae-ad581b38fa90",
   "metadata": {},
   "source": [
    "# K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0ffd6-dcb6-46f0-9fbb-896f2c9cac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold1 /Epoch0, Train loss: 0.7427005842328072, Acc: 0.5193798449612403, F1-Macro: 0.34543222506393867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [01:05<09:51, 65.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Epoch/0, Val loss: 0.8346105962991714, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Fold1 /Epoch1, Train loss: 0.7440792731940746, Acc: 0.5213178294573644, F1-Macro: 0.3462893720475773\n",
      "Fold1 Epoch/1, Val loss: 0.8263923078775406, Acc: 0.5384615384615384, F1-Macro: 0.35\n",
      "Validation loss decreased 0.8346105962991714 -> 0.8263923078775406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [02:08<08:37, 64.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch2, Train loss: 0.7254938073456287, Acc: 0.5310077519379846, F1-Macro: 0.3680950549561768\n",
      "Fold1 Epoch/2, Val loss: 0.890519380569458, Acc: 0.5461538461538461, F1-Macro: 0.35323383084577115\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [03:13<07:33, 64.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch3, Train loss: 0.7106706202030182, Acc: 0.5426356589147286, F1-Macro: 0.39637156736393375\n",
      "Fold1 Epoch/3, Val loss: 0.810938373208046, Acc: 0.5538461538461539, F1-Macro: 0.3857934180514826\n",
      "Validation loss decreased 0.8263923078775406 -> 0.810938373208046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [04:15<06:25, 64.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch4, Train loss: 0.6955053471028805, Acc: 0.6085271317829457, F1-Macro: 0.5425210674157304\n",
      "Fold1 Epoch/4, Val loss: 0.7810432612895966, Acc: 0.6153846153846154, F1-Macro: 0.5486111111111112\n",
      "Validation loss decreased 0.810938373208046 -> 0.7810432612895966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [05:20<05:22, 64.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch5, Train loss: 0.6720440573990345, Acc: 0.6531007751937985, F1-Macro: 0.6299741602067184\n",
      "Fold1 Epoch/5, Val loss: 0.7287380322813988, Acc: 0.6230769230769231, F1-Macro: 0.5971159319461135\n",
      "Validation loss decreased 0.7810432612895966 -> 0.7287380322813988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [06:25<04:17, 64.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch6, Train loss: 0.66154420748353, Acc: 0.6763565891472868, F1-Macro: 0.6668870101705923\n",
      "Fold1 Epoch/6, Val loss: 0.709716722369194, Acc: 0.6461538461538462, F1-Macro: 0.6314102564102564\n",
      "Validation loss decreased 0.7287380322813988 -> 0.709716722369194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [07:28<03:11, 63.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch7, Train loss: 0.619407158344984, Acc: 0.689922480620155, F1-Macro: 0.6869834240737651\n",
      "Fold1 Epoch/7, Val loss: 0.7269643694162369, Acc: 0.6846153846153846, F1-Macro: 0.6761650161006136\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [08:30<02:07, 63.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch8, Train loss: 0.5986521020531654, Acc: 0.7131782945736435, F1-Macro: 0.710002278423331\n",
      "Fold1 Epoch/8, Val loss: 0.7539373338222504, Acc: 0.676923076923077, F1-Macro: 0.6655231560891939\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [09:32<01:03, 63.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 /Epoch9, Train loss: 0.596578374505043, Acc: 0.7151162790697675, F1-Macro: 0.7118424501673436\n",
      "Fold1 Epoch/9, Val loss: 0.6739756166934967, Acc: 0.6538461538461539, F1-Macro: 0.635718288810013\n",
      "Validation loss decreased 0.709716722369194 -> 0.6739756166934967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [10:35<00:00, 63.60s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "Fold2 /Epoch0, Train loss: 0.5831297691911459, Acc: 0.7214700193423598, F1-Macro: 0.7177947598253276\n",
      "Fold2 Epoch/0, Val loss: 0.5544275641441345, Acc: 0.7441860465116279, F1-Macro: 0.7378855981774521\n",
      "Validation loss decreased 0.6739756166934967 -> 0.5544275641441345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [01:04<09:44, 64.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch1, Train loss: 0.548838185146451, Acc: 0.7408123791102514, F1-Macro: 0.7376230874109984\n",
      "Fold2 Epoch/1, Val loss: 0.6002339497208595, Acc: 0.751937984496124, F1-Macro: 0.7422577422577422\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [02:10<08:40, 65.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch2, Train loss: 0.5236177463084459, Acc: 0.769825918762089, F1-Macro: 0.7682967705489125\n",
      "Fold2 Epoch/2, Val loss: 0.6088904961943626, Acc: 0.7829457364341085, F1-Macro: 0.7807187955318116\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [03:15<07:36, 65.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch3, Train loss: 0.4867596458643675, Acc: 0.804642166344294, F1-Macro: 0.8023228962003082\n",
      "Fold2 Epoch/3, Val loss: 0.655955083668232, Acc: 0.7906976744186046, F1-Macro: 0.7882031012465796\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [04:16<06:23, 63.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch4, Train loss: 0.4466446340084076, Acc: 0.8413926499032882, F1-Macro: 0.8400709219858156\n",
      "Fold2 Epoch/4, Val loss: 0.49790878780186176, Acc: 0.7751937984496124, F1-Macro: 0.7732314966357519\n",
      "Validation loss decreased 0.5544275641441345 -> 0.49790878780186176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [05:20<05:19, 63.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch5, Train loss: 0.36929700523614883, Acc: 0.8878143133462283, F1-Macro: 0.8871043040872264\n",
      "Fold2 Epoch/5, Val loss: 0.4978867173194885, Acc: 0.8062015503875969, F1-Macro: 0.8045099108928897\n",
      "Validation loss decreased 0.49790878780186176 -> 0.4978867173194885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [06:23<04:14, 63.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch6, Train loss: 0.3198184398934245, Acc: 0.9168278529980658, F1-Macro: 0.9164665787407048\n",
      "Fold2 Epoch/6, Val loss: 0.4459234643727541, Acc: 0.813953488372093, F1-Macro: 0.8136735676456427\n",
      "Validation loss decreased 0.4978867173194885 -> 0.4459234643727541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [07:26<03:10, 63.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch7, Train loss: 0.21123469062149525, Acc: 0.9593810444874274, F1-Macro: 0.9592438126198904\n",
      "Fold2 Epoch/7, Val loss: 0.5919243022799492, Acc: 0.7984496124031008, F1-Macro: 0.7984375\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [08:33<02:08, 64.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch8, Train loss: 0.15956835495308042, Acc: 0.9903288201160542, F1-Macro: 0.9903079339964682\n",
      "Fold2 Epoch/8, Val loss: 0.5439034774899483, Acc: 0.751937984496124, F1-Macro: 0.7493929091792133\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [09:36<01:04, 64.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 /Epoch9, Train loss: 0.11218045721761882, Acc: 0.9845261121856866, F1-Macro: 0.9844837935174069\n",
      "Fold2 Epoch/9, Val loss: 0.5047373026609421, Acc: 0.8062015503875969, F1-Macro: 0.8057813911472448\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [10:41<00:00, 64.14s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "Fold3 /Epoch0, Train loss: 0.18314129346981645, Acc: 0.9381044487427466, F1-Macro: 0.9377502182354536\n",
      "Fold3 Epoch/0, Val loss: 0.056470471899956465, Acc: 1.0, F1-Macro: 1.0\n",
      "Validation loss decreased 0.4459234643727541 -> 0.056470471899956465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [01:04<09:44, 64.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch1, Train loss: 0.17840692540630698, Acc: 0.9400386847195358, F1-Macro: 0.9397465346832435\n",
      "Fold3 Epoch/1, Val loss: 0.2784133795648813, Acc: 0.8837209302325582, F1-Macro: 0.8830179553835923\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [02:10<08:40, 65.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch2, Train loss: 0.15876897191628814, Acc: 0.9555125725338491, F1-Macro: 0.9553622709646419\n",
      "Fold3 Epoch/2, Val loss: 0.11259909966611303, Acc: 0.9534883720930233, F1-Macro: 0.9534855769230768\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [03:12<07:30, 64.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch3, Train loss: 0.11582414852455258, Acc: 0.9613152804642167, F1-Macro: 0.9611371700042096\n",
      "Fold3 Epoch/3, Val loss: 0.09929165696667042, Acc: 0.9612403100775194, F1-Macro: 0.961203007518797\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [04:20<06:31, 65.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch4, Train loss: 0.1289943023584783, Acc: 0.9690522243713733, F1-Macro: 0.9688751091177268\n",
      "Fold3 Epoch/4, Val loss: 0.3206979457754642, Acc: 0.8217054263565892, F1-Macro: 0.8181651038793896\n",
      "Early stopping counter 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [05:29<05:32, 66.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch5, Train loss: 0.21047746716067195, Acc: 0.9245647969052224, F1-Macro: 0.9243735301729473\n",
      "Fold3 Epoch/5, Val loss: 0.13020522519946098, Acc: 0.9689922480620154, F1-Macro: 0.9689455946076071\n",
      "Early stopping counter 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [06:47<04:40, 70.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch6, Train loss: 0.15496550407260656, Acc: 0.9477756286266924, F1-Macro: 0.9473215465026322\n",
      "Fold3 Epoch/6, Val loss: 0.13166536204516888, Acc: 0.9612403100775194, F1-Macro: 0.9612403100775194\n",
      "Early stopping counter 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [08:10<03:40, 73.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch7, Train loss: 0.10811321553774178, Acc: 0.9613152804642167, F1-Macro: 0.9611371700042096\n",
      "Fold3 Epoch/7, Val loss: 0.41196136347571155, Acc: 0.8449612403100775, F1-Macro: 0.8428362573099415\n",
      "Early stopping counter 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [09:30<02:31, 75.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch8, Train loss: 0.06845024472568184, Acc: 0.9806576402321083, F1-Macro: 0.9805878465651379\n",
      "Fold3 Epoch/8, Val loss: 0.13324839249253273, Acc: 0.9612403100775194, F1-Macro: 0.9612403100775194\n",
      "Early stopping counter 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [10:34<01:12, 72.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 /Epoch9, Train loss: 0.07427348115015775, Acc: 0.988394584139265, F1-Macro: 0.9883527079390827\n",
      "Fold3 Epoch/9, Val loss: 0.25768998079001904, Acc: 0.9069767441860465, F1-Macro: 0.9069264069264068\n",
      "Early stopping counter 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [11:35<00:00, 69.52s/it]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "Fold4 /Epoch0, Train loss: 0.2511172275990248, Acc: 0.9052224371373307, F1-Macro: 0.9048107525184776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [01:00<?, ?it/s]\n",
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Epoch/0, Val loss: 0.07686681768313974, Acc: 0.9844961240310077, F1-Macro: 0.9842836257309941\n",
      "Early stopping counter 10/10\n",
      "Early stopped\n",
      "Fold 5\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "    \n",
    "\n",
    "    for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "\n",
    "        trainer.train_epoch(fold, train_loader, epoch_index)\n",
    "        trainer.validate_epoch(fold, test_loader, epoch_index)\n",
    "\n",
    "        # early_stopping check\n",
    "        early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "        if early_stopper.stop:\n",
    "            print('Early stopped')\n",
    "            break\n",
    "\n",
    "        if early_stopper.save_model:           \n",
    "            check_point = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            torch.save(check_point, 'best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
   "metadata": {},
   "source": [
    "### epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.7150068382422129, Acc: 0.5679862306368331, F1-Macro: 0.5596371553413597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:43<06:31, 43.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 1.0537893772125244, Acc: 0.6153846153846154, F1-Macro: 0.5905769715293524\n",
      "Epoch 1, Train loss: 0.6220975004964404, Acc: 0.6764199655765921, F1-Macro: 0.6764190069913497\n",
      "Epoch 1, Val loss: 0.8865877091884613, Acc: 0.5076923076923077, F1-Macro: 0.3627450980392157\n",
      "Validation loss decreased 1.0537893772125244 -> 0.8865877091884613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [01:26<05:47, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.5785027659601636, Acc: 0.7005163511187608, F1-Macro: 0.6983709273182956\n",
      "Epoch 2, Val loss: 0.5585557892918587, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Validation loss decreased 0.8865877091884613 -> 0.5585557892918587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [02:10<05:03, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.49541593260235256, Acc: 0.7728055077452668, F1-Macro: 0.7705975256646486\n",
      "Epoch 3, Val loss: 0.4888179078698158, Acc: 0.8615384615384616, F1-Macro: 0.8614072494669509\n",
      "Validation loss decreased 0.5585557892918587 -> 0.4888179078698158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [02:53<04:20, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.4270397300521533, Acc: 0.8158347676419966, F1-Macro: 0.8143476170424988\n",
      "Epoch 4, Val loss: 0.9447085410356522, Acc: 0.7692307692307693, F1-Macro: 0.767247553115302\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [03:36<03:36, 43.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.4104241347975201, Acc: 0.8450946643717728, F1-Macro: 0.8443193997856376\n",
      "Epoch 5, Val loss: 0.997687965631485, Acc: 0.8153846153846154, F1-Macro: 0.8099415204678363\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [04:18<02:51, 42.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.39116421507464516, Acc: 0.8296041308089501, F1-Macro: 0.8287926277157169\n",
      "Epoch 6, Val loss: 0.8743369281291962, Acc: 0.8, F1-Macro: 0.799239724400095\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [05:01<02:08, 42.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.3476083038581742, Acc: 0.8657487091222031, F1-Macro: 0.8655730897009968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [05:43<01:25, 42.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val loss: 0.4742511548101902, Acc: 0.7692307692307693, F1-Macro: 0.7636363636363637\n",
      "Validation loss decreased 0.4888179078698158 -> 0.4742511548101902\n",
      "Epoch 8, Train loss: 0.352601816256841, Acc: 0.8605851979345955, F1-Macro: 0.8588727452656202\n",
      "Epoch 8, Val loss: 0.4510917328298092, Acc: 0.7846153846153846, F1-Macro: 0.7833333333333333\n",
      "Validation loss decreased 0.4742511548101902 -> 0.4510917328298092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [06:27<00:42, 42.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.33472725252310437, Acc: 0.8726333907056799, F1-Macro: 0.8720568979883347\n",
      "Epoch 9, Val loss: 0.44625740870833397, Acc: 0.7846153846153846, F1-Macro: 0.7841555977229602\n",
      "Validation loss decreased 0.4510917328298092 -> 0.44625740870833397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [07:09<00:00, 42.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# for epoch_index in enumerate(tqdm(range(EPOCHS)):\n",
    "\n",
    "#     trainer.train_epoch(train_dataloader, epoch_index)\n",
    "#     trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "#     # early_stopping check\n",
    "#     early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "#     if early_stopper.stop:\n",
    "#         print('Early stopped')\n",
    "#         break\n",
    "\n",
    "#     if early_stopper.save_model:\n",
    "#         check_point = {\n",
    "#             'model': model.state_dict(),\n",
    "#             'optimizer': optimizer.state_dict(),\n",
    "#             'scheduler': scheduler.state_dict()\n",
    "#         }\n",
    "#         torch.save(check_point, 'best.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53514a-e83f-4795-9589-640f26cc2993",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = 'best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ceab2318-ee3a-43c1-91bb-3a0b5138a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2478b8d5-c566-45fc-a44c-33d156a76ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f46bd06-5950-469b-a822-79ea7331b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "densenet161(\n",
       "  (model): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer25): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer26): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer27): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer28): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer29): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer30): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer31): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer32): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer33): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer34): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer35): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer36): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Linear(in_features=2208, out_features=2, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9914e-01, 8.6040e-04],\n",
      "        [9.3875e-01, 6.1253e-02],\n",
      "        [7.2528e-01, 2.7472e-01],\n",
      "        [4.9199e-01, 5.0801e-01],\n",
      "        [9.9941e-01, 5.8897e-04],\n",
      "        [2.2381e-03, 9.9776e-01],\n",
      "        [4.0764e-03, 9.9592e-01],\n",
      "        [1.4203e-01, 8.5797e-01],\n",
      "        [9.8685e-01, 1.3153e-02],\n",
      "        [2.0924e-03, 9.9791e-01],\n",
      "        [9.9482e-01, 5.1792e-03],\n",
      "        [9.3365e-01, 6.6353e-02],\n",
      "        [9.9949e-01, 5.1246e-04],\n",
      "        [4.6101e-01, 5.3899e-01],\n",
      "        [8.8111e-01, 1.1889e-01],\n",
      "        [9.8074e-01, 1.9263e-02],\n",
      "        [7.1969e-01, 2.8031e-01],\n",
      "        [9.9944e-01, 5.5629e-04],\n",
      "        [8.4606e-01, 1.5394e-01],\n",
      "        [9.9798e-01, 2.0173e-03],\n",
      "        [9.9804e-01, 1.9580e-03],\n",
      "        [9.8610e-01, 1.3897e-02],\n",
      "        [8.6028e-01, 1.3972e-01],\n",
      "        [8.5035e-01, 1.4965e-01],\n",
      "        [9.7851e-04, 9.9902e-01],\n",
      "        [9.9562e-01, 4.3769e-03],\n",
      "        [9.9464e-01, 5.3586e-03],\n",
      "        [1.7690e-01, 8.2310e-01],\n",
      "        [2.3516e-02, 9.7648e-01],\n",
      "        [4.2739e-01, 5.7261e-01],\n",
      "        [4.5407e-02, 9.5459e-01],\n",
      "        [3.0617e-03, 9.9694e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.0640e-01, 1.9360e-01],\n",
      "        [9.8737e-01, 1.2627e-02],\n",
      "        [9.9123e-01, 8.7693e-03],\n",
      "        [1.1274e-02, 9.8873e-01],\n",
      "        [3.5710e-01, 6.4290e-01],\n",
      "        [8.2763e-02, 9.1724e-01],\n",
      "        [3.5589e-03, 9.9644e-01],\n",
      "        [9.0481e-01, 9.5191e-02],\n",
      "        [5.2442e-04, 9.9948e-01],\n",
      "        [7.9600e-01, 2.0400e-01],\n",
      "        [6.9956e-01, 3.0044e-01],\n",
      "        [1.9566e-03, 9.9804e-01],\n",
      "        [2.6712e-01, 7.3288e-01],\n",
      "        [9.8614e-01, 1.3860e-02],\n",
      "        [6.8384e-02, 9.3162e-01],\n",
      "        [2.0698e-01, 7.9302e-01],\n",
      "        [9.7225e-03, 9.9028e-01],\n",
      "        [9.9985e-01, 1.5208e-04],\n",
      "        [3.4690e-01, 6.5310e-01],\n",
      "        [2.5228e-03, 9.9748e-01],\n",
      "        [1.7010e-01, 8.2990e-01],\n",
      "        [8.6156e-01, 1.3844e-01],\n",
      "        [1.8574e-02, 9.8143e-01],\n",
      "        [5.3056e-01, 4.6944e-01],\n",
      "        [7.4469e-01, 2.5531e-01],\n",
      "        [1.8442e-03, 9.9816e-01],\n",
      "        [6.0988e-01, 3.9012e-01],\n",
      "        [8.3839e-01, 1.6161e-01],\n",
      "        [9.6630e-03, 9.9034e-01],\n",
      "        [9.8745e-01, 1.2554e-02],\n",
      "        [9.9653e-01, 3.4716e-03],\n",
      "        [9.9847e-01, 1.5252e-03]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.6927e-02, 9.0307e-01],\n",
      "        [2.5529e-03, 9.9745e-01],\n",
      "        [7.4387e-04, 9.9926e-01],\n",
      "        [9.1563e-01, 8.4366e-02],\n",
      "        [1.5205e-01, 8.4795e-01],\n",
      "        [9.9648e-01, 3.5231e-03],\n",
      "        [9.2908e-01, 7.0916e-02],\n",
      "        [9.9881e-01, 1.1883e-03],\n",
      "        [9.6086e-01, 3.9142e-02],\n",
      "        [9.9915e-01, 8.4809e-04],\n",
      "        [4.0098e-05, 9.9996e-01],\n",
      "        [6.4274e-01, 3.5726e-01],\n",
      "        [9.9974e-01, 2.6495e-04],\n",
      "        [9.9953e-01, 4.6974e-04],\n",
      "        [4.3393e-02, 9.5661e-01],\n",
      "        [2.6261e-02, 9.7374e-01],\n",
      "        [2.0469e-04, 9.9980e-01],\n",
      "        [1.4122e-02, 9.8588e-01],\n",
      "        [9.4505e-01, 5.4954e-02],\n",
      "        [5.3405e-01, 4.6595e-01],\n",
      "        [4.7794e-02, 9.5221e-01],\n",
      "        [1.2612e-01, 8.7388e-01],\n",
      "        [9.8218e-01, 1.7824e-02],\n",
      "        [1.0751e-01, 8.9249e-01],\n",
      "        [9.9690e-01, 3.1016e-03],\n",
      "        [2.1478e-01, 7.8522e-01],\n",
      "        [3.4888e-01, 6.5112e-01],\n",
      "        [4.9273e-01, 5.0727e-01],\n",
      "        [1.3538e-02, 9.8646e-01],\n",
      "        [1.1736e-02, 9.8826e-01],\n",
      "        [9.9971e-01, 2.8596e-04],\n",
      "        [9.7745e-01, 2.2548e-02]], device='cuda:0')\n",
      "tensor([[0.0031, 0.9969],\n",
      "        [0.0039, 0.9961],\n",
      "        [0.0443, 0.9557],\n",
      "        [0.8974, 0.1026]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
   "metadata": {},
   "source": [
    "### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('densenet161.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380e162-e63a-46b6-8700-8989a8a813d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d26da-7e0c-4098-bc1f-4c1e6ad9e2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3649d3-b49c-448e-86c0-8d45a7a9615e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b5456-d8a7-40b0-852e-a493282a08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690278dd-d257-4a5b-a638-a09d436d9df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
