{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
   "metadata": {},
   "source": [
    "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
    "- 이미지 binary 분류 과제\n",
    "- 담당: 이녕민M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4325d39-6344-4116-b343-df51696905ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt-get update && apt-get install -y python3-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "6f475804-13db-484c-a348-f01580e80a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# ! pip install mxnet\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c40829-3e7c-4d26-9737-ff712c9bfaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet\n",
      "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.3 MB 23.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.8/site-packages (from mxnet) (1.19.2)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from mxnet) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.9.0\n"
     ]
    }
   ],
   "source": [
    "! pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import mxnet as mx\n",
    "import random\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
   "metadata": {},
   "source": [
    "## Set Arguments & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드(seed) 설정\n",
    "\n",
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= 'data'\n",
    "NUM_CLS = 2\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "INPUT_SHAPE = 256 # 크게하는게 좋다고 함\n",
    "\n",
    "k = 5\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
   "metadata": {},
   "source": [
    "#### Train & Validation Set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04642777-c2e0-439b-9692-f6c571a86521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.8)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.8):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        # self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "        #                                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #                                      transforms.ToTensor(),\n",
    "        #                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        self.transform = albumentations.Compose([albumentations.Resize(256, 256), \n",
    "                                                 albumentations.RandomCrop(240, 240),\n",
    "                                                 albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "                                                 albumentations.VerticalFlip(),\n",
    "                                                 albumentations.ChannelShuffle(0.05),\n",
    "                                                 albumentations.RandomBrightnessContrast(p=0.5),\n",
    "                                                albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                albumentations.pytorch.transforms.ToTensorV2()])\n",
    "        \n",
    "        \n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        image = cv2.cvtColor(cvimg, cv2.COLOR_BGR2RGB)\n",
    "        trans_image = self.transform(image = image)\n",
    "        trans_image = trans_image['image']\n",
    "        \n",
    "        \n",
    "        # trans_image = self.transform(Image.fromarray(cvimg))\n",
    "        \n",
    "\n",
    "        return trans_image, data['COVID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# class custom_CNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(custom_CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
    "        \n",
    "#         self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
    "#         self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
    "#         x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
    "        \n",
    "#         x = torch.flatten(x,1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        \n",
    "#         output = self.softmax(x)\n",
    "        \n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cb6193-5c8c-4330-9f2d-4bae23d27b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class resnet(nn.Module):\n",
    "    def __init__(self, numclasses):\n",
    "        super(resnet, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, numclasses)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_img):\n",
    "        x = self.model(input_img)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2bfdb2-888b-4973-8e52-3a2919e70d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "\n",
    "# class vgg16(nn.Module):\n",
    "#     def __init__(self, numclasses):\n",
    "#         super(vgg16, self).__init__()\n",
    "#         self.model = models.vgg16(pretrained=False)\n",
    "#         self.model.classifier[6] = nn.Linear(in_features=4096, out_features=numclasses, bias=True)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self, input_img):\n",
    "#         x = self.model(input_img)\n",
    "#         x = self.softmax(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de8813e-5aa5-42a9-82c2-9f7353498643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "\n",
    "# class resnet152(nn.Module):\n",
    "#     def __init__(self, numclasses):\n",
    "#         super(resnet152, self).__init__()\n",
    "#         self.model = models.resnet152(pretrained=False)\n",
    "#         self.model.fc = nn.Linear(self.model.fc.in_features, numclasses)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self, input_img):\n",
    "#         x = self.model(input_img)\n",
    "#         x = self.softmax(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b37d808-39ad-4363-ab8c-545a8737536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "\n",
    "# class regnet_6gf(nn.Module):\n",
    "#     def __init__(self, numclasses):\n",
    "#         super(regnet_6gf, self).__init__()\n",
    "#         self.model = models.regnet_y_1_6gf(pretrained=False)\n",
    "#         self.model.fc = nn.Linear(self.model.fc.in_features, numclasses)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self, input_img):\n",
    "#         x = self.model(input_img)\n",
    "#         x = self.softmax(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056905-1f77-4579-a260-07bb1056f6db",
   "metadata": {},
   "source": [
    "## Utils\n",
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" epoch에 대한 학습 및 검증 절차 정의\"\"\"\n",
    "    \n",
    "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            \n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            \n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device).float()\n",
    "            pred = self.model(img)\n",
    "            \n",
    "            loss = self.loss_fn(pred[:,1], label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
    "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train\n",
    "### 학습을 위한 객체 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 516 Val set samples: 130\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913fb617-5910-4ead-982b-485ea231195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 516 Val set samples: 130\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader (ab)\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "\n",
    "dataset = ConcatDataset([train_dataset, validation_dataset])\n",
    "splits=KFold(n_splits=k,shuffle=True, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
   "metadata": {},
   "source": [
    "#### Load model and other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "# model = custom_CNN(NUM_CLS).to(DEVICE)\n",
    "model = resnet(NUM_CLS).to(DEVICE)\n",
    "\n",
    "# # Save Initial Model\n",
    "# torch.save(model.state_dict(), 'initial.pt')\n",
    "\n",
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = get_metric_fn\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc014a9-9c2e-4214-bd3f-e84ccabc7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
   "metadata": {},
   "source": [
    "### epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.7261331677436829, Acc: 0.5852713178294574, F1-Macro: 0.580328367284889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 1/50 [00:07<06:30,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.7711303010582924, Acc: 0.6076923076923076, F1-Macro: 0.5770334928229665\n",
      "Epoch 1, Train loss: 0.6551164649426937, Acc: 0.6492248062015504, F1-Macro: 0.6340726635871035\n",
      "Epoch 1, Val loss: 0.7365354672074318, Acc: 0.6076923076923076, F1-Macro: 0.6037296037296038\n",
      "Validation loss decreased 0.7711303010582924 -> 0.7365354672074318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 2/50 [00:16<06:25,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.659119681455195, Acc: 0.6492248062015504, F1-Macro: 0.6363749625263289\n",
      "Epoch 2, Val loss: 1.5394302615895867, Acc: 0.5, F1-Macro: 0.34653159075090867\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 3/50 [00:25<06:40,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6544293370097876, Acc: 0.6434108527131783, F1-Macro: 0.6371086105675148\n",
      "Epoch 3, Val loss: 0.7541439458727837, Acc: 0.6461538461538462, F1-Macro: 0.6420019157088123\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% 4/50 [00:35<06:53,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.5959951309487224, Acc: 0.689922480620155, F1-Macro: 0.685672514619883\n",
      "Epoch 4, Val loss: 0.791638195514679, Acc: 0.5846153846153846, F1-Macro: 0.5458074534161491\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 5/50 [00:45<06:56,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.5920975208282471, Acc: 0.7073643410852714, F1-Macro: 0.7037493298657449\n",
      "Epoch 5, Val loss: 0.93836809694767, Acc: 0.5153846153846153, F1-Macro: 0.4272326736135394\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% 6/50 [00:55<06:57,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.6096597202122211, Acc: 0.6763565891472868, F1-Macro: 0.671769478355267\n",
      "Epoch 6, Val loss: 0.6051926193758845, Acc: 0.7307692307692307, F1-Macro: 0.7294726202509068\n",
      "Validation loss decreased 0.7365354672074318 -> 0.6051926193758845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 7/50 [01:05<06:53,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.5645154174417257, Acc: 0.7170542635658915, F1-Macro: 0.7126335062557216\n",
      "Epoch 7, Val loss: 0.6462962441146374, Acc: 0.6384615384615384, F1-Macro: 0.6382689005979516\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 8/50 [01:16<06:52,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 0.5779885705560446, Acc: 0.7228682170542635, F1-Macro: 0.7196834719314975\n",
      "Epoch 8, Val loss: 0.8559350222349167, Acc: 0.5923076923076923, F1-Macro: 0.570957095709571\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 9/50 [01:26<06:45,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.6120411902666092, Acc: 0.6763565891472868, F1-Macro: 0.6729057457477214\n",
      "Epoch 9, Val loss: 0.9005577862262726, Acc: 0.6307692307692307, F1-Macro: 0.592156862745098\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 10/50 [01:36<06:39,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 0.577921912074089, Acc: 0.7209302325581395, F1-Macro: 0.7168422175815131\n",
      "Epoch 10, Val loss: 0.695855900645256, Acc: 0.6461538461538462, F1-Macro: 0.6458185264155414\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 11/50 [01:46<06:33, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 0.5561549076810479, Acc: 0.7441860465116279, F1-Macro: 0.7388143262520133\n",
      "Epoch 11, Val loss: 1.075347177684307, Acc: 0.6076923076923076, F1-Macro: 0.5487032877271799\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 12/50 [01:56<06:24, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 0.614737126044929, Acc: 0.689922480620155, F1-Macro: 0.6884057971014493\n",
      "Epoch 12, Val loss: 0.7816725820302963, Acc: 0.6538461538461539, F1-Macro: 0.6426608026388125\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% 13/50 [02:06<06:14, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 0.5505671771243215, Acc: 0.7422480620155039, F1-Macro: 0.7350587381433109\n",
      "Epoch 13, Val loss: 0.7233399413526058, Acc: 0.6, F1-Macro: 0.5965624253998567\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28% 14/50 [02:17<06:12, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 0.5618736818432808, Acc: 0.7228682170542635, F1-Macro: 0.7207443486948919\n",
      "Epoch 14, Val loss: 0.934422954916954, Acc: 0.5538461538461539, F1-Macro: 0.45219412961348443\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 15/50 [02:28<06:04, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 0.5837524477392435, Acc: 0.7054263565891473, F1-Macro: 0.6995771281485568\n",
      "Epoch 15, Val loss: 0.7437494210898876, Acc: 0.6076923076923076, F1-Macro: 0.5971808736861293\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% 16/50 [02:38<05:55, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 0.5507284728810191, Acc: 0.7441860465116279, F1-Macro: 0.7419530823786143\n",
      "Epoch 16, Val loss: 0.6891757510602474, Acc: 0.6923076923076923, F1-Macro: 0.6920161099265577\n",
      "Early stopping counter 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% 17/50 [02:49<05:44, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 0.5212436693254858, Acc: 0.7558139534883721, F1-Macro: 0.7547491512636741\n",
      "Epoch 17, Val loss: 0.7721664309501648, Acc: 0.6461538461538462, F1-Macro: 0.6458185264155414\n",
      "Early stopping counter 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 18/50 [02:59<05:31, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 0.5331531669944525, Acc: 0.748062015503876, F1-Macro: 0.7454771733851384\n",
      "Epoch 18, Val loss: 0.7399983182549477, Acc: 0.6538461538461539, F1-Macro: 0.6533333333333333\n",
      "Early stopping counter 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 19/50 [03:09<05:21, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train loss: 0.5371314957737923, Acc: 0.7383720930232558, F1-Macro: 0.7320923792858105\n",
      "Epoch 19, Val loss: 0.7910054177045822, Acc: 0.6692307692307692, F1-Macro: 0.6603681876177168\n",
      "Early stopping counter 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 20/50 [03:20<05:10, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train loss: 0.5271640010178089, Acc: 0.7713178294573644, F1-Macro: 0.7691502752544017\n",
      "Epoch 20, Val loss: 0.9309655055403709, Acc: 0.5615384615384615, F1-Macro: 0.47413242495209706\n",
      "Early stopping counter 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [03:30<05:01, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train loss: 0.5498710423707962, Acc: 0.7383720930232558, F1-Macro: 0.7349062886499858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [03:39<05:02, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Val loss: 0.7178863473236561, Acc: 0.7153846153846154, F1-Macro: 0.714962962962963\n",
      "Early stopping counter 15/15\n",
      "Early stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "    trainer.train_epoch(train_dataloader, epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if early_stopper.save_model:\n",
    "        check_point = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        torch.save(check_point, 'best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f678cd-5966-4468-a441-202715ec22e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 0, Train loss: 0.7261331677436829, Acc: 0.5852713178294574, F1-Macro: 0.580328367284889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 1/50 [00:08<06:45,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.7711303010582924, Acc: 0.6076923076923076, F1-Macro: 0.5770334928229665\n",
      "Epoch 1, Train loss: 0.6551164649426937, Acc: 0.6492248062015504, F1-Macro: 0.6340726635871035\n",
      "Epoch 1, Val loss: 0.7365354672074318, Acc: 0.6076923076923076, F1-Macro: 0.6037296037296038\n",
      "Validation loss decreased 0.7711303010582924 -> 0.7365354672074318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4% 2/50 [00:16<06:39,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.659119681455195, Acc: 0.6492248062015504, F1-Macro: 0.6363749625263289\n",
      "Epoch 2, Val loss: 1.5394302615895867, Acc: 0.5, F1-Macro: 0.34653159075090867\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% 3/50 [00:26<06:55,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6544293370097876, Acc: 0.6434108527131783, F1-Macro: 0.6371086105675148\n",
      "Epoch 3, Val loss: 0.7541439458727837, Acc: 0.6461538461538462, F1-Macro: 0.6420019157088123\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8% 4/50 [00:36<07:05,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.5959951309487224, Acc: 0.689922480620155, F1-Macro: 0.685672514619883\n",
      "Epoch 4, Val loss: 0.791638195514679, Acc: 0.5846153846153846, F1-Macro: 0.5458074534161491\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 5/50 [00:47<07:09,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 0.5920975208282471, Acc: 0.7073643410852714, F1-Macro: 0.7037493298657449\n",
      "Epoch 5, Val loss: 0.93836809694767, Acc: 0.5153846153846153, F1-Macro: 0.4272326736135394\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12% 6/50 [00:57<07:07,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 0.6096597202122211, Acc: 0.6763565891472868, F1-Macro: 0.671769478355267\n",
      "Epoch 6, Val loss: 0.6051926193758845, Acc: 0.7307692307692307, F1-Macro: 0.7294726202509068\n",
      "Validation loss decreased 0.7365354672074318 -> 0.6051926193758845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14% 7/50 [01:07<07:01,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 0.5645154174417257, Acc: 0.7170542635658915, F1-Macro: 0.7126335062557216\n",
      "Epoch 7, Val loss: 0.6462962441146374, Acc: 0.6384615384615384, F1-Macro: 0.6382689005979516\n",
      "Early stopping counter 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16% 8/50 [01:17<06:56,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 0.5779885705560446, Acc: 0.7228682170542635, F1-Macro: 0.7196834719314975\n",
      "Epoch 8, Val loss: 0.8559350222349167, Acc: 0.5923076923076923, F1-Macro: 0.570957095709571\n",
      "Early stopping counter 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18% 9/50 [01:27<06:52, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 0.6120411902666092, Acc: 0.6763565891472868, F1-Macro: 0.6729057457477214\n",
      "Epoch 9, Val loss: 0.9005577862262726, Acc: 0.6307692307692307, F1-Macro: 0.592156862745098\n",
      "Early stopping counter 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 10/50 [01:38<06:43, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 0.577921912074089, Acc: 0.7209302325581395, F1-Macro: 0.7168422175815131\n",
      "Epoch 10, Val loss: 0.695855900645256, Acc: 0.6461538461538462, F1-Macro: 0.6458185264155414\n",
      "Early stopping counter 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22% 11/50 [01:48<06:34, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 0.5561549076810479, Acc: 0.7441860465116279, F1-Macro: 0.7388143262520133\n",
      "Epoch 11, Val loss: 1.075347177684307, Acc: 0.6076923076923076, F1-Macro: 0.5487032877271799\n",
      "Early stopping counter 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24% 12/50 [01:58<06:27, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 0.614737126044929, Acc: 0.689922480620155, F1-Macro: 0.6884057971014493\n",
      "Epoch 12, Val loss: 0.7816725820302963, Acc: 0.6538461538461539, F1-Macro: 0.6426608026388125\n",
      "Early stopping counter 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% 13/50 [02:09<06:21, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 0.5505671771243215, Acc: 0.7422480620155039, F1-Macro: 0.7350587381433109\n",
      "Epoch 13, Val loss: 0.7233399413526058, Acc: 0.6, F1-Macro: 0.5965624253998567\n",
      "Early stopping counter 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28% 14/50 [02:19<06:08, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 0.5618736818432808, Acc: 0.7228682170542635, F1-Macro: 0.7207443486948919\n",
      "Epoch 14, Val loss: 0.934422954916954, Acc: 0.5538461538461539, F1-Macro: 0.45219412961348443\n",
      "Early stopping counter 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 15/50 [02:29<05:58, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 0.5837524477392435, Acc: 0.7054263565891473, F1-Macro: 0.6995771281485568\n",
      "Epoch 15, Val loss: 0.7437494210898876, Acc: 0.6076923076923076, F1-Macro: 0.5971808736861293\n",
      "Early stopping counter 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32% 16/50 [02:39<05:46, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 0.5507284728810191, Acc: 0.7441860465116279, F1-Macro: 0.7419530823786143\n",
      "Epoch 16, Val loss: 0.6891757510602474, Acc: 0.6923076923076923, F1-Macro: 0.6920161099265577\n",
      "Early stopping counter 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34% 17/50 [02:49<05:37, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 0.5212436693254858, Acc: 0.7558139534883721, F1-Macro: 0.7547491512636741\n",
      "Epoch 17, Val loss: 0.7721664309501648, Acc: 0.6461538461538462, F1-Macro: 0.6458185264155414\n",
      "Early stopping counter 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% 18/50 [03:00<05:27, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 0.5331531669944525, Acc: 0.748062015503876, F1-Macro: 0.7454771733851384\n",
      "Epoch 18, Val loss: 0.7399983182549477, Acc: 0.6538461538461539, F1-Macro: 0.6533333333333333\n",
      "Early stopping counter 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38% 19/50 [03:10<05:16, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train loss: 0.5371314957737923, Acc: 0.7383720930232558, F1-Macro: 0.7320923792858105\n",
      "Epoch 19, Val loss: 0.7910054177045822, Acc: 0.6692307692307692, F1-Macro: 0.6603681876177168\n",
      "Early stopping counter 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 20/50 [03:20<05:06, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train loss: 0.5271640010178089, Acc: 0.7713178294573644, F1-Macro: 0.7691502752544017\n",
      "Epoch 20, Val loss: 0.9309655055403709, Acc: 0.5615384615384615, F1-Macro: 0.47413242495209706\n",
      "Early stopping counter 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [03:31<05:00, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train loss: 0.5498710423707962, Acc: 0.7383720930232558, F1-Macro: 0.7349062886499858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42% 21/50 [03:39<05:03, 10.45s/it]\n",
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Val loss: 0.7178863473236561, Acc: 0.7153846153846154, F1-Macro: 0.714962962962963\n",
      "Early stopping counter 15/15\n",
      "Early stopped\n",
      "Fold 2\n",
      "Epoch 0, Train loss: 0.4916765494272113, Acc: 0.7693798449612403, F1-Macro: 0.7674504917685109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:08<?, ?it/s]\n",
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.6773093864321709, Acc: 0.7076923076923077, F1-Macro: 0.7074153044302298\n",
      "Early stopping counter 16/15\n",
      "Early stopped\n",
      "Fold 3\n",
      "Epoch 0, Train loss: 0.5174215184524655, Acc: 0.7616279069767442, F1-Macro: 0.7592763270182625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:08<?, ?it/s]\n",
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.8852848708629608, Acc: 0.6461538461538462, F1-Macro: 0.6201727642276422\n",
      "Early stopping counter 17/15\n",
      "Early stopped\n",
      "Fold 4\n",
      "Epoch 0, Train loss: 0.523485753685236, Acc: 0.7577519379844961, F1-Macro: 0.7540861727801988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:08<?, ?it/s]\n",
      "  0% 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.7241522297263145, Acc: 0.6384615384615384, F1-Macro: 0.6267790605338709\n",
      "Early stopping counter 18/15\n",
      "Early stopped\n",
      "Fold 5\n",
      "Epoch 0, Train loss: 0.4861377524212003, Acc: 0.7829457364341085, F1-Macro: 0.7828935505199255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/50 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.6216891596559435, Acc: 0.7153846153846154, F1-Macro: 0.715232964300515\n",
      "Early stopping counter 19/15\n",
      "Early stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "    \n",
    "\n",
    "    for epoch_index in tqdm(range(EPOCHS)):\n",
    "\n",
    "        trainer.train_epoch(train_dataloader, epoch_index)\n",
    "        trainer.validate_epoch(validation_dataloader, epoch_index)\n",
    "\n",
    "        # early_stopping check\n",
    "        early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "        if early_stopper.stop:\n",
    "            print('Early stopped')\n",
    "            break\n",
    "\n",
    "        if early_stopper.save_model:\n",
    "            check_point = {\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "            }\n",
    "            torch.save(check_point, 'best2.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53514a-e83f-4795-9589-640f26cc2993",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = 'best.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        # self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "        #                                      transforms.ToTensor(),\n",
    "        #                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        self.transform = albumentations.Compose([albumentations.Resize(256, 256), \n",
    "                                                 albumentations.RandomCrop(240, 240),\n",
    "                                                 albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "                                                 albumentations.VerticalFlip(),\n",
    "                                                 albumentations.ChannelShuffle(0.05),\n",
    "                                                 albumentations.RandomBrightnessContrast(p=0.5),\n",
    "                                                albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        \n",
    "\n",
    "        # Preprocessing images\n",
    "        image = cv2.cvtColor(cvimg, cv2.COLOR_BGR2RGB)\n",
    "        trans_image = self.transform(image = image)\n",
    "        trans_image = trans_image['image']\n",
    "        \n",
    "        \n",
    "        # trans_image = self.transform(Image.fromarray(cvimg))\n",
    "        \n",
    "\n",
    "        # trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99b57b3-dea8-4dc4-992a-4c21310956ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9757, 0.0243],\n",
      "        [0.9431, 0.0569],\n",
      "        [0.8767, 0.1233],\n",
      "        [0.9714, 0.0286],\n",
      "        [0.9574, 0.0426],\n",
      "        [0.3201, 0.6799],\n",
      "        [0.7686, 0.2314],\n",
      "        [0.9028, 0.0972],\n",
      "        [0.9660, 0.0340],\n",
      "        [0.3462, 0.6538],\n",
      "        [0.9215, 0.0785],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.9298, 0.0702],\n",
      "        [0.9682, 0.0318],\n",
      "        [0.9835, 0.0165],\n",
      "        [0.9090, 0.0910]], device='cuda:0')\n",
      "tensor([[0.9303, 0.0697],\n",
      "        [0.9533, 0.0467],\n",
      "        [0.9395, 0.0605],\n",
      "        [0.8969, 0.1031],\n",
      "        [0.9768, 0.0232],\n",
      "        [0.8742, 0.1258],\n",
      "        [0.9290, 0.0710],\n",
      "        [0.8877, 0.1123],\n",
      "        [0.6265, 0.3735],\n",
      "        [0.9659, 0.0341],\n",
      "        [0.9648, 0.0352],\n",
      "        [0.9414, 0.0586],\n",
      "        [0.1227, 0.8773],\n",
      "        [0.9291, 0.0709],\n",
      "        [0.9269, 0.0731],\n",
      "        [0.5304, 0.4696]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5432, 0.4568],\n",
      "        [0.9781, 0.0219],\n",
      "        [0.9077, 0.0923],\n",
      "        [0.8528, 0.1472],\n",
      "        [0.9430, 0.0570],\n",
      "        [0.7342, 0.2658],\n",
      "        [0.4813, 0.5187],\n",
      "        [0.8800, 0.1200],\n",
      "        [0.7283, 0.2717],\n",
      "        [0.8763, 0.1237],\n",
      "        [0.7490, 0.2510],\n",
      "        [0.5749, 0.4251],\n",
      "        [0.8896, 0.1104],\n",
      "        [0.7538, 0.2462],\n",
      "        [0.9098, 0.0902],\n",
      "        [0.9658, 0.0342]], device='cuda:0')\n",
      "tensor([[0.9526, 0.0474],\n",
      "        [0.9406, 0.0594],\n",
      "        [0.9205, 0.0795],\n",
      "        [0.7294, 0.2706],\n",
      "        [0.9293, 0.0707],\n",
      "        [0.7726, 0.2274],\n",
      "        [0.7726, 0.2274],\n",
      "        [0.9563, 0.0437],\n",
      "        [0.8631, 0.1369],\n",
      "        [0.8501, 0.1499],\n",
      "        [0.9328, 0.0672],\n",
      "        [0.7410, 0.2590],\n",
      "        [0.5924, 0.4076],\n",
      "        [0.9736, 0.0264],\n",
      "        [0.9641, 0.0359],\n",
      "        [0.9007, 0.0993]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6243, 0.3757],\n",
      "        [0.5096, 0.4904],\n",
      "        [0.3725, 0.6275],\n",
      "        [0.9044, 0.0956],\n",
      "        [0.7050, 0.2950],\n",
      "        [0.7875, 0.2125],\n",
      "        [0.9264, 0.0736],\n",
      "        [0.9811, 0.0189],\n",
      "        [0.7783, 0.2217],\n",
      "        [0.9311, 0.0689],\n",
      "        [0.5832, 0.4168],\n",
      "        [0.8889, 0.1111],\n",
      "        [0.9913, 0.0087],\n",
      "        [0.9727, 0.0273],\n",
      "        [0.8295, 0.1705],\n",
      "        [0.9150, 0.0850]], device='cuda:0')\n",
      "tensor([[0.5453, 0.4547],\n",
      "        [0.8736, 0.1264],\n",
      "        [0.9181, 0.0819],\n",
      "        [0.3679, 0.6321],\n",
      "        [0.6930, 0.3070],\n",
      "        [0.7859, 0.2141],\n",
      "        [0.8787, 0.1213],\n",
      "        [0.9458, 0.0542],\n",
      "        [0.9524, 0.0476],\n",
      "        [0.8641, 0.1359],\n",
      "        [0.8767, 0.1233],\n",
      "        [0.9788, 0.0212],\n",
      "        [0.9405, 0.0595],\n",
      "        [0.9004, 0.0996],\n",
      "        [0.9907, 0.0093],\n",
      "        [0.8588, 0.1412]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:01,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7176, 0.2824],\n",
      "        [0.8504, 0.1496],\n",
      "        [0.5633, 0.4367],\n",
      "        [0.6125, 0.3875]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "\n",
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
   "metadata": {},
   "source": [
    "### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
